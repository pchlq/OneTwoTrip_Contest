{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "370.6px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea43701c0cb44697bb180648cc97de18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79059ecd6a994b658cc0b0d6136df72a",
              "IPY_MODEL_80bf60894cef4be8a2e43d3c0605fa60"
            ],
            "layout": "IPY_MODEL_ff945c11c1fb438aa4089d39938616ba"
          }
        },
        "ff945c11c1fb438aa4089d39938616ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79059ecd6a994b658cc0b0d6136df72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Optimization Progress: ",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5934a5a7d55644108e5993725f83ce95",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5df86d604604d9d8dfb6a9a927588b3",
            "value": 20
          }
        },
        "80bf60894cef4be8a2e43d3c0605fa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21cf21b8ae344c1cb39688f484935ea7",
            "placeholder": "​",
            "style": "IPY_MODEL_a4f7266640a24787a3deccb699bb2367",
            "value": " 51/? [1:01:34&lt;00:00, 141.04s/pipeline]"
          }
        },
        "a5df86d604604d9d8dfb6a9a927588b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "5934a5a7d55644108e5993725f83ce95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f7266640a24787a3deccb699bb2367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21cf21b8ae344c1cb39688f484935ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4effa211e0e04927b762555779af5773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06f127a8ab964bd1bfef336ed5d9a458",
              "IPY_MODEL_05ae147f4a82477e90d63fc0bd2efd23"
            ],
            "layout": "IPY_MODEL_a4220273ab5e42219b88ad4170ca48ba"
          }
        },
        "a4220273ab5e42219b88ad4170ca48ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f127a8ab964bd1bfef336ed5d9a458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "Optimization Progress:  45%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2328471642d7471e897fa85036e67472",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b7a6d00bf8451b8da0fe935ca30650",
            "value": 9
          }
        },
        "05ae147f4a82477e90d63fc0bd2efd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5a6186682c492dbc290c9f7370412b",
            "placeholder": "​",
            "style": "IPY_MODEL_5b0d5656ba644f68b428f2a28e12cc3e",
            "value": " 9/20 [05:04&lt;11:10, 60.99s/pipeline]"
          }
        },
        "24b7a6d00bf8451b8da0fe935ca30650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "2328471642d7471e897fa85036e67472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b0d5656ba644f68b428f2a28e12cc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e5a6186682c492dbc290c9f7370412b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f55b507d084ed888cd3ad4219c6093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_915409f20fa84b02966d3a519a564276",
              "IPY_MODEL_2fb378c35df04c079be611e5df985ec9"
            ],
            "layout": "IPY_MODEL_57823476d44c49c883619e583c433378"
          }
        },
        "57823476d44c49c883619e583c433378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "915409f20fa84b02966d3a519a564276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Optimization Progress: ",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7121e8647a6745deb573eea2f9a754be",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c05d9070741e4b2286692364f41bb507",
            "value": 15
          }
        },
        "2fb378c35df04c079be611e5df985ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f578a356739e4c1ab0bd19d1c42a8ebd",
            "placeholder": "​",
            "style": "IPY_MODEL_11c4801327544003a1a504d0ac38eb88",
            "value": " 18/? [28:21&lt;00:00, 162.27s/pipeline]"
          }
        },
        "c05d9070741e4b2286692364f41bb507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7121e8647a6745deb573eea2f9a754be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11c4801327544003a1a504d0ac38eb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f578a356739e4c1ab0bd19d1c42a8ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-20T10:22:05.733772Z",
          "start_time": "2019-12-20T10:22:05.512051Z"
        },
        "colab_type": "code",
        "id": "hwiGUg9YS1eP",
        "outputId": "20079281-ca3c-44f8-d202-101af7444f01",
        "colab": {}
      },
      "source": [
        "!python -V"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.4\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HwAvKWGq-_Fg",
        "colab": {}
      },
      "source": [
        "# !pip install feature-engine\n",
        "# !pip install optuna\n",
        "# # !pip install featexp\n",
        "# !pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHSUJqMpmhh_",
        "colab": {}
      },
      "source": [
        "from featexp import get_univariate_plots\n",
        "from featexp import univariate_plotter\n",
        "from featexp import get_trend_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v7HbhKJlS1en"
      },
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-23T08:05:34.195354Z",
          "start_time": "2019-12-23T08:05:32.186030Z"
        },
        "colab_type": "code",
        "id": "jtU15JXkS1eo",
        "outputId": "84ebfddf-7f7e-402a-b0bf-376a1838de24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from __future__ import division, print_function\n",
        "import gc\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.linalg import svd\n",
        "from numba import jit\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "from contextlib import contextmanager\n",
        "from collections import namedtuple\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.pipeline import Pipeline as pipe\n",
        "from feature_engine import categorical_encoders as ce\n",
        "from feature_engine import discretisers as dsc\n",
        "import concurrent.futures\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import (cross_val_score, train_test_split, ShuffleSplit, StratifiedKFold, KFold,\n",
        "                                    learning_curve, TimeSeriesSplit, RepeatedKFold)\n",
        "\n",
        "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
        "                             VotingClassifier, ExtraTreesClassifier)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from scipy import stats \n",
        "from scipy.special import boxcox1p\n",
        "\n",
        "from scipy.stats import rankdata\n",
        "from sklearn.preprocessing import (MinMaxScaler, Binarizer, StandardScaler, OneHotEncoder,\n",
        "                                  Normalizer, RobustScaler, OrdinalEncoder, LabelEncoder)\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier, plot_importance, plot_metric\n",
        "import xgboost as xgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "\n",
        "pd.set_option('display.max_columns', 130)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBrA3QpBWbZP",
        "colab": {}
      },
      "source": [
        "colab_path = '/content/drive/My Drive/'\n",
        "pickle.dump(mapper_fit, open('fitted_mapper.pkl', 'wb'))\n",
        "# mapper_fit = pickle.load(open('fitted_mapper.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGhxBy217zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_path = '/content/drive/My Drive/'\n",
        "# with open( os.path.join(colab_path,'list_dict.json'), 'w') as fp:\n",
        "#     json.dump(list_dicts, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "btaGImoaTSjP",
        "outputId": "2e63ebc5-317a-4d31-ef6a-12584eed2dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhHqD4HFC_v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_train_path = pathlib.Path('/content/drive/My Drive/ott_train')\n",
        "Xtrain = pd.read_pickle(colab_train_path/'train.pkl')\n",
        "Xtest = pd.read_pickle(colab_train_path/'test.pkl')\n",
        "targets = pd.read_pickle(colab_train_path/'targets.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0OZzCEHFEFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = targets['goal24']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FfClAEGNS1et"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-23T08:05:37.106354Z",
          "start_time": "2019-12-23T08:05:37.084994Z"
        },
        "colab_type": "code",
        "id": "N_hbRcCpS1eu",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n",
        "\n",
        "@jit\n",
        "def fast_auc(y_true, y_prob):\n",
        "    \"\"\"\n",
        "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    nfalse = 0\n",
        "    auc = 0\n",
        "    n = len(y_true)\n",
        "    for i in range(n):\n",
        "        y_i = y_true[i]\n",
        "        nfalse += (1 - y_i)\n",
        "        auc += y_i * nfalse\n",
        "    auc /= (nfalse * (n - nfalse))\n",
        "    return auc\n",
        "\n",
        "def eval_auc(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Fast auc eval function for lgb.\n",
        "    \"\"\"\n",
        "    return 'auc', fast_auc(y_true, y_pred), True\n",
        "\n",
        "\n",
        "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', \n",
        "                               columns=None, plot_feature_importance=False, model=None,\n",
        "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n",
        "    \"\"\"\n",
        "    A function to train a variety of regression models.\n",
        "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
        "    \n",
        "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
        "    :params: y - target\n",
        "    :params: folds - folds to split data\n",
        "    :params: model_type - type of model to use\n",
        "    :params: eval_metric - metric to use\n",
        "    :params: columns - columns to use. If None - use all columns\n",
        "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
        "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
        "    \n",
        "    \"\"\"\n",
        "    columns = X.columns if columns == None else columns\n",
        "    X_test = X_test[columns]\n",
        "    \n",
        "    # to set up scoring parameters\n",
        "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
        "                        'catboost_metric_name': 'AUC',\n",
        "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
        "                    }\n",
        "    \n",
        "    result_dict = {}\n",
        "    \n",
        "    # out-of-fold predictions on train data\n",
        "    oof = np.zeros((len(X), len(set(y.values))))\n",
        "    \n",
        "    # averaged predictions on train data\n",
        "    prediction = np.zeros((len(X_test), oof.shape[1]))\n",
        "    \n",
        "    # list of scores on folds\n",
        "    scores = []\n",
        "    feature_importance = pd.DataFrame()\n",
        "    \n",
        "    # split and train on folds\n",
        "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
        "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
        "        if type(X) == np.ndarray:\n",
        "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
        "            y_train, y_valid = y[train_index], y[valid_index]\n",
        "        else:\n",
        "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
        "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "            \n",
        "        if model_type == 'lgb':\n",
        "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = -1)\n",
        "            model.fit(X_train, y_train, \n",
        "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
        "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
        "            \n",
        "            y_pred_valid = model.predict_proba(X_valid)\n",
        "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
        "            \n",
        "        if model_type == 'xgb':\n",
        "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
        "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
        "\n",
        "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
        "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, \n",
        "                              early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
        "            \n",
        "            y_pred_valid = model.predict_proba(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "            y_pred = model.predict_proba(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
        "        \n",
        "        if model_type == 'sklearn':\n",
        "            model = model\n",
        "            model.fit(X_train, y_train)\n",
        "            \n",
        "            y_pred_valid = model.predict_proba(X_valid).reshape(-1,)\n",
        "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
        "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
        "            print('')\n",
        "            \n",
        "            y_pred = model.predict_proba(X_test)\n",
        "        \n",
        "        if model_type == 'cat':\n",
        "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params)\n",
        "                                      #loss_function='CrossEntropy') #  metrics_dict[eval_metric]['catboost_metric_name'])\n",
        "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=cats_indices, plot=True, use_best_model=True, verbose=False) # cats_indices\n",
        "\n",
        "            y_pred_valid = model.predict_proba(X_valid)\n",
        "            y_pred = model.predict_proba(X_test)\n",
        "        \n",
        "        oof[valid_index] = y_pred_valid\n",
        "        scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1]))\n",
        "\n",
        "        prediction += y_pred    \n",
        "        \n",
        "        if model_type == 'lgb' and plot_feature_importance:\n",
        "            # feature importance\n",
        "            fold_importance = pd.DataFrame()\n",
        "            fold_importance[\"feature\"] = columns\n",
        "            fold_importance[\"importance\"] = model.feature_importances_\n",
        "            fold_importance[\"fold\"] = fold_n + 1\n",
        "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
        "\n",
        "    prediction /= folds.n_splits\n",
        "    \n",
        "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
        "    \n",
        "    result_dict['oof'] = oof\n",
        "    result_dict['prediction'] = prediction\n",
        "    result_dict['scores'] = scores\n",
        "    \n",
        "    if model_type == 'lgb':\n",
        "        if plot_feature_importance:\n",
        "            feature_importance[\"importance\"] /= folds.n_splits\n",
        "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
        "                by=\"importance\", ascending=False)[:50].index\n",
        "\n",
        "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
        "\n",
        "            plt.figure(figsize=(16, 12));\n",
        "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
        "            plt.title('LGB Features (avg over folds)');\n",
        "            \n",
        "            result_dict['feature_importance'] = feature_importance\n",
        "        \n",
        "    return result_dict\n",
        "\n",
        "def make_harmonic_features(df, column):\n",
        "    for col in column:\n",
        "        period = df[col].nunique()\n",
        "        value = df[col].copy()\n",
        "        value *= 2 * np.pi / period\n",
        "        df[col + '_cos'] = np.cos(value, dtype='float32')\n",
        "        df[col + '_sin'] = np.sin(value, dtype='float32')\n",
        "    return (df)\n",
        "\n",
        "def make_conj(data, feat1, feat2):\n",
        "    \"\"\"\n",
        "    inplace\n",
        "    \"\"\"\n",
        "    new_name = feat1 + '_' + feat2\n",
        "    data[new_name] = data[feat1].astype(str)+ '_' + data[feat2].astype(str)\n",
        "    data[new_name] = LabelEncoder().fit_transform(data[new_name])\n",
        "    \n",
        "\n",
        "# по значениям другого категориального признака\n",
        "def code_factor(data, cat_feature, cat_feature2):\n",
        "    ct = pd.crosstab(data[cat_feature], data[cat_feature2])\n",
        "    u, _, _ = svd(ct.values)\n",
        "    coder = dict(zip(ct.index, u[:, 0])) # если кодирование первой компонентой\n",
        "    return (data[cat_feature].map(coder))\n",
        "\n",
        "def make_real_feature(df, name, group_col='userid'):\n",
        "    \"\"\"\n",
        "    вычисление разных статистик\n",
        "    \"\"\"\n",
        "    tmp = df.groupby(group_col)[name].agg({np.mean, max, min, np.median, sum, np.std}).fillna(-1)\n",
        "    tmp.columns = [name + '_' + str(x) for x in tmp.columns]\n",
        "    tmp = tmp.reset_index()\n",
        "    return (tmp[tmp.columns[tmp.nunique()>1]])\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "def load_ottrip(train=True):\n",
        "\n",
        "  cols_to_rename = {'field0': 'ndays_from_last',\n",
        "                 'field2': 'month_buy',\n",
        "                 'field3': 'month_depart',\n",
        "                 'field4': 'order_of_buy',\n",
        "                 'field9': 'ticket_child_1y',\n",
        "                 'field11': 'hour_of_buy',\n",
        "                 'field15': 'total_tickets',\n",
        "                 'field16': 'days_before_depart',\n",
        "                 'field18': 'dow_buy',\n",
        "                 'field20': 'dow_depart',\n",
        "                 'field21': 'year',\n",
        "                 'field23': 'hour_depart',\n",
        "                 'field24': 'ticket_adult',\n",
        "                 'field28': 'ticket_child_4y',\n",
        "                 'field29': 'quarter'}\n",
        "\n",
        "  for k, v in cols_to_rename.items():\n",
        "    cols_to_rename[k] = v.upper() \n",
        "\n",
        "  train_file = 'onetwotrip_challenge_train.csv'\n",
        "  test_file = 'onetwotrip_challenge_test.csv'\n",
        "  f = train_file if train else test_file\n",
        "  colab_path = '/content/drive/My Drive/'\n",
        "  data = pd.read_csv(os.path.join(colab_path , f))\n",
        "  data.rename(columns=cols_to_rename, inplace=True)\n",
        "\n",
        "  data['YEAR']=(data.YEAR == 1).astype(uint16)\n",
        "  data['field7']=(data.field7 == 1).astype(uint16)\n",
        "  data['userid'] = LabelEncoder().fit_transform(data.userid)\n",
        "  data['USR_CNT'] = data.userid.map(data.groupby('userid').size())\n",
        "  indicator_cols=list(filter(lambda x: 'indicat' in x, data.columns))\n",
        "  data['INDICATOR_CNT'] = data[indicator_cols].apply(lambda x: np.sum(x.astype(uint8))/5, axis=1).astype(np.float16)\n",
        "  data = reduce_mem_usage(data)\n",
        "  print(data.shape)\n",
        "\n",
        "  return data\n",
        "\n",
        "def load_ottrip_without_userid_encoding(train=True):\n",
        "\n",
        "  cols_to_rename = {'field0': 'ndays_from_last',\n",
        "                 'field2': 'month_buy',\n",
        "                 'field3': 'month_depart',\n",
        "                 'field4': 'order_of_buy',\n",
        "                 'field9': 'ticket_child_1y',\n",
        "                 'field11': 'hour_of_buy',\n",
        "                 'field15': 'total_tickets',\n",
        "                 'field16': 'days_before_depart',\n",
        "                 'field18': 'dow_buy',\n",
        "                 'field20': 'dow_depart',\n",
        "                 'field21': 'year',\n",
        "                 'field23': 'hour_depart',\n",
        "                 'field24': 'ticket_adult',\n",
        "                 'field28': 'ticket_child_4y',\n",
        "                 'field29': 'quarter'}\n",
        "\n",
        "  for k, v in cols_to_rename.items():\n",
        "    cols_to_rename[k] = v.upper() \n",
        "\n",
        "  train_file = 'onetwotrip_challenge_train.csv'\n",
        "  test_file = 'onetwotrip_challenge_test.csv'\n",
        "  f = train_file if train else test_file\n",
        "  colab_path = '/content/drive/My Drive/'\n",
        "  data = pd.read_csv(os.path.join(colab_path , f))\n",
        "  data.rename(columns=cols_to_rename, inplace=True)\n",
        "\n",
        "  data['YEAR']=(data.YEAR == 1).astype(uint16)\n",
        "  data['field7']=(data.field7 == 1).astype(uint16)\n",
        "  indicator_cols=list(filter(lambda x: 'indicat' in x, data.columns))\n",
        "  data['INDICATOR_CNT'] = data[indicator_cols].apply(lambda x: np.sum(x.astype(uint8))/5, axis=1).astype(np.float16)\n",
        "  data = reduce_mem_usage(data)\n",
        "  print(data.shape)\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def drop_corr_cols(df, upper_tresh=0.9):\n",
        "  corr_matrix = df.corr().abs()\n",
        "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "  to_drop = [column for column in upper.columns if any(upper[column] > upper_tresh)]\n",
        "\n",
        "  return to_drop\n",
        "\n",
        "colab_subm_path = '/content/drive/My Drive/ottrip_subm/'\n",
        "colab_path = '/content/drive/My Drive/'\n",
        "\n",
        "SEED = 17\n",
        "TEST_SIZE = 0.3\n",
        "SPLITS = 10\n",
        "\n",
        "# ==== cv strategy ====\n",
        "shuffle_split = ShuffleSplit(n_splits=SPLITS, test_size=TEST_SIZE, random_state=SEED)\n",
        "skf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R-EB1K4fS1ey"
      },
      "source": [
        "# Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-12-23T08:05:52.378220Z",
          "start_time": "2019-12-23T08:05:51.504294Z"
        },
        "colab_type": "code",
        "id": "P9r92wtlS1ez",
        "outputId": "9374ca59-bb49-49f3-9dc5-f4ba90f8286b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "df = load_ottrip()\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 15.71 Mb (75.4% reduction)\n",
            "(196056, 45)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orderid</th>\n",
              "      <th>userid</th>\n",
              "      <th>NDAYS_FROM_LAST</th>\n",
              "      <th>field1</th>\n",
              "      <th>MONTH_BUY</th>\n",
              "      <th>MONTH_DEPART</th>\n",
              "      <th>ORDER_OF_BUY</th>\n",
              "      <th>field5</th>\n",
              "      <th>field6</th>\n",
              "      <th>field7</th>\n",
              "      <th>field8</th>\n",
              "      <th>TICKET_CHILD_1Y</th>\n",
              "      <th>field10</th>\n",
              "      <th>HOUR_OF_BUY</th>\n",
              "      <th>field12</th>\n",
              "      <th>field13</th>\n",
              "      <th>field14</th>\n",
              "      <th>TOTAL_TICKETS</th>\n",
              "      <th>DAYS_BEFORE_DEPART</th>\n",
              "      <th>field17</th>\n",
              "      <th>DOW_BUY</th>\n",
              "      <th>field19</th>\n",
              "      <th>DOW_DEPART</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>field22</th>\n",
              "      <th>HOUR_DEPART</th>\n",
              "      <th>TICKET_ADULT</th>\n",
              "      <th>field25</th>\n",
              "      <th>field26</th>\n",
              "      <th>field27</th>\n",
              "      <th>TICKET_CHILD_4Y</th>\n",
              "      <th>QUARTER</th>\n",
              "      <th>indicator_goal21</th>\n",
              "      <th>indicator_goal22</th>\n",
              "      <th>indicator_goal23</th>\n",
              "      <th>indicator_goal24</th>\n",
              "      <th>indicator_goal25</th>\n",
              "      <th>goal21</th>\n",
              "      <th>goal22</th>\n",
              "      <th>goal23</th>\n",
              "      <th>goal24</th>\n",
              "      <th>goal25</th>\n",
              "      <th>goal1</th>\n",
              "      <th>USR_CNT</th>\n",
              "      <th>INDICATOR_CNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7458</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.626508</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>-0.661308</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>33232</td>\n",
              "      <td>144</td>\n",
              "      <td>-0.393794</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>125</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.101043</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>121</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>83136</td>\n",
              "      <td>134</td>\n",
              "      <td>-0.548937</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.661308</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1583</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.238651</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.521242</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>93298</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.704079</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.801375</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.600098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   orderid  userid  NDAYS_FROM_LAST    field1  MONTH_BUY  MONTH_DEPART  \\\n",
              "0        0    7458                0 -0.626508         11            12   \n",
              "1        1   33232              144 -0.393794          5             7   \n",
              "2        2   83136              134 -0.548937          2             3   \n",
              "3        3    1583                0 -0.238651         10            11   \n",
              "4        4   93298                0 -0.704079          8            11   \n",
              "\n",
              "   ORDER_OF_BUY  field5  field6  field7  field8  TICKET_CHILD_1Y  field10  \\\n",
              "0             1       1       0       1       1                0        0   \n",
              "1             2       0       0       0       1                0        0   \n",
              "2             2       0       0       1       1                0        1   \n",
              "3             1       1       3       0       1                0        0   \n",
              "4             1       1       0       1       1                0        1   \n",
              "\n",
              "   HOUR_OF_BUY  field12  field13   field14  TOTAL_TICKETS  DAYS_BEFORE_DEPART  \\\n",
              "0            9        5       20 -0.661308              1                   4   \n",
              "1           21      125        3 -0.101043              1                  57   \n",
              "2            7        4        3 -0.661308              1                   4   \n",
              "3           19       12        3 -0.521242              2                  22   \n",
              "4           16        4        3 -0.801375              1                 100   \n",
              "\n",
              "   field17  DOW_BUY  field19  DOW_DEPART  YEAR  field22  HOUR_DEPART  \\\n",
              "0        1        4        1           1     1        1           15   \n",
              "1        1        5        1           6     0      121           15   \n",
              "2        1        2        3           6     0       17           14   \n",
              "3        1        3        3           4     1       46           12   \n",
              "4        1        6        1           1     1       17           22   \n",
              "\n",
              "   TICKET_ADULT  field25  field26  field27  TICKET_CHILD_4Y  QUARTER  \\\n",
              "0             1        1        2        1                0        4   \n",
              "1             1       41        3        1                0        2   \n",
              "2             1        1       11        7                0        1   \n",
              "3             2       18        1        1                0        4   \n",
              "4             1        1        1        1                0        3   \n",
              "\n",
              "   indicator_goal21  indicator_goal22  indicator_goal23  indicator_goal24  \\\n",
              "0                 1                 1                 0                 1   \n",
              "1                 1                 1                 0                 1   \n",
              "2                 1                 1                 0                 1   \n",
              "3                 1                 1                 0                 1   \n",
              "4                 1                 1                 0                 0   \n",
              "\n",
              "   indicator_goal25  goal21  goal22  goal23  goal24  goal25  goal1  USR_CNT  \\\n",
              "0                 1       0       1       0       0       0      0        1   \n",
              "1                 0       0       0       0       0       0      0        2   \n",
              "2                 1       0       0       0       0       0      0        2   \n",
              "3                 1       0       0       0       0       0      0        3   \n",
              "4                 1       0       0       0       0       0      0        1   \n",
              "\n",
              "   INDICATOR_CNT  \n",
              "0       0.799805  \n",
              "1       0.600098  \n",
              "2       0.799805  \n",
              "3       0.799805  \n",
              "4       0.600098  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClTkX4aoZ8d7",
        "colab": {}
      },
      "source": [
        "indicator_cols=list(filter(lambda x: 'indicat' in x, df.columns))\n",
        "goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "cat_cols=['MONTH_BUY', 'MONTH_DEPART', 'field5', 'field7', 'field8',\n",
        " 'field10', 'DOW_BUY', 'DOW_DEPART', 'YEAR', 'HOUR_DEPART', 'field27', 'QUARTER']+indicator_cols+goals_cols\n",
        "\n",
        "to_harmonic_cols =['MONTH_BUY', 'MONTH_DEPART', 'HOUR_OF_BUY', 'HOUR_DEPART', 'DOW_BUY', \n",
        "                  'DOW_DEPART', 'QUARTER', 'field27']\n",
        "\n",
        "to_ohe_cols = ['MONTH_BUY', 'MONTH_DEPART', 'HOUR_OF_BUY', 'HOUR_DEPART', 'DOW_BUY', 'DOW_DEPART', 'QUARTER', 'field27']\n",
        "\n",
        "make_real_feats=['ORDER_OF_BUY', 'TICKET_CHILD_1Y', 'DAYS_BEFORE_DEPART',\n",
        "       'DIFF_HOUR_DEPART&HOUR_OF_BUY', 'DIFF_MONTH_DEPART&MONTH_BUY',\n",
        "       'field1', 'field12', 'field13', 'field14', 'field17', 'field19',\n",
        "       'field22', 'field25', 'field26', 'field6', 'INDICATOR_CNT', 'NDAYS_FROM_LAST',\n",
        "       'NDAYS_LAST_NEXT', 'TICKET_ADULT', 'TICKET_CHILD_4Y','TOTAL_TICKETS', 'USR_CNT', 'WEEKS_BEFORE_DEPART']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OJDPdd9vxKPY",
        "outputId": "c97b9a0d-2813-4ed0-c886-bc1f87183402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "df_test = load_ottrip(train=False)\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 33.85 Mb (73.5% reduction)\n",
            "(455011, 39)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orderid</th>\n",
              "      <th>userid</th>\n",
              "      <th>NDAYS_FROM_LAST</th>\n",
              "      <th>field1</th>\n",
              "      <th>MONTH_BUY</th>\n",
              "      <th>MONTH_DEPART</th>\n",
              "      <th>ORDER_OF_BUY</th>\n",
              "      <th>field5</th>\n",
              "      <th>field6</th>\n",
              "      <th>field7</th>\n",
              "      <th>field8</th>\n",
              "      <th>TICKET_CHILD_1Y</th>\n",
              "      <th>field10</th>\n",
              "      <th>HOUR_OF_BUY</th>\n",
              "      <th>field12</th>\n",
              "      <th>field13</th>\n",
              "      <th>field14</th>\n",
              "      <th>TOTAL_TICKETS</th>\n",
              "      <th>DAYS_BEFORE_DEPART</th>\n",
              "      <th>field17</th>\n",
              "      <th>DOW_BUY</th>\n",
              "      <th>field19</th>\n",
              "      <th>DOW_DEPART</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>field22</th>\n",
              "      <th>HOUR_DEPART</th>\n",
              "      <th>TICKET_ADULT</th>\n",
              "      <th>field25</th>\n",
              "      <th>field26</th>\n",
              "      <th>field27</th>\n",
              "      <th>TICKET_CHILD_4Y</th>\n",
              "      <th>QUARTER</th>\n",
              "      <th>indicator_goal21</th>\n",
              "      <th>indicator_goal22</th>\n",
              "      <th>indicator_goal23</th>\n",
              "      <th>indicator_goal24</th>\n",
              "      <th>indicator_goal25</th>\n",
              "      <th>USR_CNT</th>\n",
              "      <th>INDICATOR_CNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60209</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.548937</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>-0.521242</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>47274</td>\n",
              "      <td>82</td>\n",
              "      <td>-0.626508</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.661308</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>33843</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.548937</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.521242</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>245314</td>\n",
              "      <td>6</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>0.879422</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>168484</td>\n",
              "      <td>115</td>\n",
              "      <td>-0.471365</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.661308</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.799805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   orderid  userid  NDAYS_FROM_LAST    field1  MONTH_BUY  MONTH_DEPART  \\\n",
              "0        0   60209                0 -0.548937         10            10   \n",
              "1        1   47274               82 -0.626508          3             4   \n",
              "2        2   33843                0 -0.548937          6             8   \n",
              "3        3  245314                6  0.304348          7             7   \n",
              "4        4  168484              115 -0.471365          3             3   \n",
              "\n",
              "   ORDER_OF_BUY  field5  field6  field7  field8  TICKET_CHILD_1Y  field10  \\\n",
              "0             1       1       0       1       1                0        1   \n",
              "1             3       0       0       1       1                0        1   \n",
              "2             1       1       0       0       1                0        1   \n",
              "3             2       0      10       1       0                0        0   \n",
              "4             2       0       0       1       1                0        1   \n",
              "\n",
              "   HOUR_OF_BUY  field12  field13   field14  TOTAL_TICKETS  DAYS_BEFORE_DEPART  \\\n",
              "0           23        2       23 -0.521242              1                   1   \n",
              "1           14        4        3 -0.661308              1                  19   \n",
              "2           13        4        3 -0.521242              1                  39   \n",
              "3           20       19        3  0.879422              1                  18   \n",
              "4           20        4        5 -0.661308              2                   8   \n",
              "\n",
              "   field17  DOW_BUY  field19  DOW_DEPART  YEAR  field22  HOUR_DEPART  \\\n",
              "0        1        2        2           3     1       20           15   \n",
              "1        1        6        1           4     0       17           14   \n",
              "2        1        1        1           5     1      101            8   \n",
              "3        1        4        1           1     1       16           16   \n",
              "4        1        2        1           3     0        1           13   \n",
              "\n",
              "   TICKET_ADULT  field25  field26  field27  TICKET_CHILD_4Y  QUARTER  \\\n",
              "0             1        1        1        1                0        4   \n",
              "1             1        1        1        1                0        1   \n",
              "2             1       35        1        1                0        2   \n",
              "3             1        1        3        1                0        3   \n",
              "4             2        1        1        1                0        1   \n",
              "\n",
              "   indicator_goal21  indicator_goal22  indicator_goal23  indicator_goal24  \\\n",
              "0                 1                 1                 0                 0   \n",
              "1                 1                 1                 0                 1   \n",
              "2                 1                 0                 0                 1   \n",
              "3                 1                 1                 0                 1   \n",
              "4                 1                 1                 0                 1   \n",
              "\n",
              "   indicator_goal25  USR_CNT  INDICATOR_CNT  \n",
              "0                 1        2       0.600098  \n",
              "1                 1        3       0.799805  \n",
              "2                 1        2       0.600098  \n",
              "3                 1        2       0.799805  \n",
              "4                 1        2       0.799805  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYTamCQ6Faz0",
        "colab_type": "text"
      },
      "source": [
        "# SUBM 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3w5YPcnbMGL"
      },
      "source": [
        "## subm2 base 0.715428"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uAP2JUkEbbHA",
        "colab": {}
      },
      "source": [
        "# Load dataset\n",
        "def load_ottrip(train=True):\n",
        "\n",
        "  cols_to_rename = {'field0': 'ndays_from_last',\n",
        "                 'field2': 'month_buy',\n",
        "                 'field3': 'month_depart',\n",
        "                 'field4': 'order_of_buy',\n",
        "                 'field9': 'ticket_child_1y',\n",
        "                 'field11': 'hour_of_buy',\n",
        "                 'field15': 'total_tickets',\n",
        "                 'field16': 'days_before_depart',\n",
        "                 'field18': 'dow_buy',\n",
        "                 'field20': 'dow_depart',\n",
        "                 'field21': 'year',\n",
        "                 'field23': 'hour_depart',\n",
        "                 'field24': 'ticket_adult',\n",
        "                 'field28': 'ticket_child_4y',\n",
        "                 'field29': 'quarter'}\n",
        "\n",
        "  for k, v in cols_to_rename.items():\n",
        "    cols_to_rename[k] = v.upper() \n",
        "\n",
        "  train_file = 'onetwotrip_challenge_train.csv'\n",
        "  test_file = 'onetwotrip_challenge_test.csv'\n",
        "  f = train_file if train else test_file\n",
        "  colab_path = '/content/drive/My Drive/'\n",
        "  data = pd.read_csv(os.path.join(colab_path , f))\n",
        "  data.rename(columns=cols_to_rename, inplace=True)\n",
        "\n",
        "  data['YEAR']=(data.YEAR == 1).astype(uint16)\n",
        "  data['field7']=(data.field7 == 1).astype(uint16)\n",
        "  data = reduce_mem_usage(data)\n",
        "  print(data.shape)\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8cY6SPVqbbP_",
        "colab": {}
      },
      "source": [
        "df = load_ottrip()\n",
        "df_test = load_ottrip(train=False)\n",
        "df_test['USR_CNT'] = df_test.userid.map(df_test.groupby('userid').size())\n",
        "df_test['INDICATOR_CNT'] = df_test[indicator_cols].apply(lambda x: np.sum(x.astype(uint8))/5, axis=1).astype(np.float16\n",
        "                                                                                                             \n",
        "to_scale = ['NDAYS_FROM_LAST', 'ORDER_OF_BUY', 'field6', 'TICKET_CHILD_1Y',\n",
        "           'field12', 'field13', 'TOTAL_TICKETS', 'DAYS_BEFORE_DEPART', 'field17', 'field19',\n",
        "           'field22', 'TICKET_ADULT', 'field25', 'field26', 'TICKET_CHILD_4Y', 'USR_CNT']\n",
        "\n",
        "df_copy = df.copy()\n",
        "df_test_copy = df_test.copy()\n",
        "scaler = RobustScaler().fit(df_copy[to_scale])\n",
        "df_copy[to_scale] = scaler.transform(df_copy[to_scale])\n",
        "df_test_copy[to_scale] = scaler.transform(df_test_copy[to_scale])                                                                                                             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uYHx8l5rbbYM",
        "colab": {}
      },
      "source": [
        "df_train=df_copy.drop(['orderid', 'userid', 'goal1'], axis=1)\n",
        "df_test=df_test_copy.drop(['orderid', 'userid'], axis=1)\n",
        "\n",
        "n_fold = 10\n",
        "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
        "list_goals = []\n",
        "\n",
        "for cycle, goal in enumerate(['goal25', 'goal23', 'goal24', 'goal22', 'goal21']):\n",
        "\n",
        "  print(f\"\\nstart training process... cycle =====> {cycle+1}\")\n",
        " \n",
        "  X = df_train.drop( np.setdiff1d(goals_cols, list_goals).tolist(), axis=1)\n",
        "  Y = df_train[goal]\n",
        "\n",
        "  used_goals = list(filter(lambda x: 'goal' in x and 'indicator' not in x, X.columns))\n",
        "\n",
        "  print(f\"use goal columns =====> {used_goals} to predict ====> {goal}\\n\")\n",
        "\n",
        "  res_dict=train_model_classification(X=X, X_test=df_test, y=Y, params=params, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                               columns=None, plot_feature_importance=False, model=None,\n",
        "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000)\n",
        "\n",
        "  list_goals.append(goal)\n",
        "\n",
        "  df_test[goal] = res_dict['prediction'][:, 1]\n",
        "\n",
        "  test_goals = list(filter(lambda x: 'goal' in x and 'indicator' not in x, df_test.columns))\n",
        "  print(f\"\\ntest set contains: {test_goals}\")\n",
        "\n",
        "  if cycle == 4:\n",
        "    probas = pd.concat([df_test['goal21'], df_test['goal22'], df_test['goal23'], \n",
        "                        df_test['goal24'], df_test['goal25']], axis=1)\n",
        "    \n",
        "    colab_path = '/content/drive/My Drive/'\n",
        "    \n",
        "    probas.to_csv( os.path.join(colab_path,'sub2.csv') )\n",
        "    print(\"process completed successfully!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mEWzdaOcaHG",
        "colab_type": "text"
      },
      "source": [
        "## 2_1  0.71597"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsn96dzXcn0h",
        "colab_type": "code",
        "outputId": "a32d8ea7-e433-4a16-e740-c45d47b380fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(X.columns.tolist(), end=', ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NDAYS_FROM_LAST', 'field1', 'MONTH_BUY', 'MONTH_DEPART', 'ORDER_OF_BUY', 'field5', 'field6', 'field7', 'field8', 'TICKET_CHILD_1Y', 'field10', 'HOUR_OF_BUY', 'field12', 'field13', 'field14', 'TOTAL_TICKETS', 'DAYS_BEFORE_DEPART', 'field17', 'DOW_BUY', 'field19', 'DOW_DEPART', 'YEAR', 'field22', 'HOUR_DEPART', 'TICKET_ADULT', 'field25', 'field26', 'field27', 'TICKET_CHILD_4Y', 'indicator_goal21', 'indicator_goal22', 'indicator_goal23', 'indicator_goal24', 'indicator_goal25', 'INDICATOR_CNT', 'USR_CNT', 'DIFF_H', 'DIFF_M', 'CHILD', 'f14_id_median', 'f1_id_median', 'f1_id_std', 'f14_id_std', 'f26_id_median', 'f27_id_median', 'f26_id_std', 'f27_id_std', 'DAYS_BEFORE_DEPART_id_median', 'DAYS_BEFORE_DEPART_id_std', 'NDAYS_FROM_LAST_id_median', 'NDAYS_FROM_LAST_id_std', 'ORDER_OF_BUY_id_median', 'ORDER_OF_BUY_id_std', 'field13_id_median', 'field13_id_std', 'field26_id_median', 'field26_id_std', 'field19_id_median', 'field19_id_std', 'field1_sem', 'field14_sem', 'field26_sem', 'field27_sem', 'field12_sem', 'NDAYS_FROM_LAST_sem', 'field13_sem', 'field22_sem', 'field25_sem', 'field1_field14', 'field26_field27'], "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeAEqjNqhJ8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_ = {'boosting': 'gbdt',\n",
        "          'objective':'binary',\n",
        "          'metric': 'auc',\n",
        "          'learning_rate': 0.01, # 0.003! #0.005 #0.006 \n",
        "          'num_leaves': 110, #110 #100 #150 large, but over-fitting\n",
        "          'max_bin': 66,  #60 #50 # large,but slower,over-fitting\n",
        "          'max_depth': 10, # deal with over-fitting\n",
        "          'min_data_in_leaf': 30, # deal with over-fitting\n",
        "          'min_child_samples': 20,\n",
        "          'feature_fraction': 0.5,#0.5 #0.6 #0.8\n",
        "          'bagging_fraction': 0.8,\n",
        "          'bagging_freq': 40,#5  \n",
        "          'bagging_seed': 11,\n",
        "          'lambda_l1': 2,#1.3! #5 #1.2 #1\n",
        "          'lambda_l2': 0.1,\n",
        "           'random_state': SEED\n",
        "         }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbObq_Wtg6VQ",
        "colab_type": "code",
        "outputId": "042bce90-5240-411f-e3ce-34071f7ae139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_train = pd.concat([X, train[goals_cols]], axis=1)\n",
        "df_test = X_test\n",
        "\n",
        "n_fold = 10\n",
        "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)\n",
        "list_goals = []\n",
        "\n",
        "for cycle, goal in enumerate(['goal25', 'goal23', 'goal24', 'goal22', 'goal21']):\n",
        "\n",
        "  print(f\"\\nstart training process... cycle =====> {cycle+1}\")\n",
        " \n",
        "  X = df_train.drop( np.setdiff1d(goals_cols, list_goals).tolist(), axis=1)\n",
        "  Y = df_train[goal]\n",
        "\n",
        "  used_goals = list(filter(lambda x: 'goal' in x and 'indicator' not in x, X.columns))\n",
        "\n",
        "  print(f\"use goal columns =====> {used_goals} to predict ====> {goal}\\n\")\n",
        "\n",
        "  res_dict=train_model_classification(X=X, X_test=df_test, y=Y, params=params_, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                               columns=None, plot_feature_importance=False, model=None,\n",
        "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000)\n",
        "\n",
        "  list_goals.append(goal)\n",
        "\n",
        "  df_test[goal] = res_dict['prediction'][:, 1]\n",
        "\n",
        "  test_goals = list(filter(lambda x: 'goal' in x and 'indicator' not in x, df_test.columns))\n",
        "  print(f\"\\ntest set contains: {test_goals}\")\n",
        "\n",
        "  if cycle == 4:\n",
        "    probas = pd.concat([df_test['goal21'], df_test['goal22'], df_test['goal23'], \n",
        "                        df_test['goal24'], df_test['goal25']], axis=1)\n",
        "    \n",
        "    colab_path = '/content/drive/My Drive/ottrip_subm/'\n",
        "    \n",
        "    probas.to_csv( os.path.join(colab_path,'sub2_1_base.csv') )\n",
        "    print(\"process completed successfully!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "start training process... cycle =====> 1\n",
            "use goal columns =====> [] to predict ====> goal25\n",
            "\n",
            "Fold 1 started at Tue Jan 14 19:25:38 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[815]\ttraining's auc: 0.988935\ttraining's auc: 0.988935\tvalid_1's auc: 0.944226\tvalid_1's auc: 0.944226\n",
            "Fold 2 started at Tue Jan 14 19:27:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[749]\ttraining's auc: 0.987901\ttraining's auc: 0.987901\tvalid_1's auc: 0.935809\tvalid_1's auc: 0.935809\n",
            "Fold 3 started at Tue Jan 14 19:29:51 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[665]\ttraining's auc: 0.985204\ttraining's auc: 0.985204\tvalid_1's auc: 0.94876\tvalid_1's auc: 0.94876\n",
            "Fold 4 started at Tue Jan 14 19:31:39 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[758]\ttraining's auc: 0.987402\ttraining's auc: 0.987402\tvalid_1's auc: 0.940902\tvalid_1's auc: 0.940902\n",
            "Fold 5 started at Tue Jan 14 19:33:42 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[495]\ttraining's auc: 0.980649\ttraining's auc: 0.980649\tvalid_1's auc: 0.941284\tvalid_1's auc: 0.941284\n",
            "Fold 6 started at Tue Jan 14 19:35:06 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[565]\ttraining's auc: 0.983686\ttraining's auc: 0.983686\tvalid_1's auc: 0.945014\tvalid_1's auc: 0.945014\n",
            "Fold 7 started at Tue Jan 14 19:36:41 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[787]\ttraining's auc: 0.989016\ttraining's auc: 0.989016\tvalid_1's auc: 0.945871\tvalid_1's auc: 0.945871\n",
            "Fold 8 started at Tue Jan 14 19:38:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[678]\ttraining's auc: 0.986283\ttraining's auc: 0.986283\tvalid_1's auc: 0.942487\tvalid_1's auc: 0.942487\n",
            "Fold 9 started at Tue Jan 14 19:40:40 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[893]\ttraining's auc: 0.990123\ttraining's auc: 0.990123\tvalid_1's auc: 0.94537\tvalid_1's auc: 0.94537\n",
            "Fold 10 started at Tue Jan 14 19:43:03 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[750]\ttraining's auc: 0.987532\ttraining's auc: 0.987532\tvalid_1's auc: 0.946862\tvalid_1's auc: 0.946862\n",
            "CV mean score: 0.9437, std: 0.0035.\n",
            "\n",
            "test set contains: ['goal25']\n",
            "\n",
            "start training process... cycle =====> 2\n",
            "use goal columns =====> ['goal25'] to predict ====> goal23\n",
            "\n",
            "Fold 1 started at Tue Jan 14 19:45:03 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1391]\ttraining's auc: 0.98452\ttraining's auc: 0.98452\tvalid_1's auc: 0.91049\tvalid_1's auc: 0.91049\n",
            "Fold 2 started at Tue Jan 14 19:48:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2337]\ttraining's auc: 0.993798\ttraining's auc: 0.993798\tvalid_1's auc: 0.910553\tvalid_1's auc: 0.910553\n",
            "Fold 3 started at Tue Jan 14 19:54:01 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2191]\ttraining's auc: 0.992811\ttraining's auc: 0.992811\tvalid_1's auc: 0.906348\tvalid_1's auc: 0.906348\n",
            "Fold 4 started at Tue Jan 14 19:59:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1606]\ttraining's auc: 0.988085\ttraining's auc: 0.988085\tvalid_1's auc: 0.912401\tvalid_1's auc: 0.912401\n",
            "Fold 5 started at Tue Jan 14 20:03:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1583]\ttraining's auc: 0.987141\ttraining's auc: 0.987141\tvalid_1's auc: 0.90994\tvalid_1's auc: 0.90994\n",
            "Fold 6 started at Tue Jan 14 20:07:06 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2565]\ttraining's auc: 0.994782\ttraining's auc: 0.994782\tvalid_1's auc: 0.910294\tvalid_1's auc: 0.910294\n",
            "Fold 7 started at Tue Jan 14 20:13:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1200]\ttraining's auc: 0.982124\ttraining's auc: 0.982124\tvalid_1's auc: 0.910238\tvalid_1's auc: 0.910238\n",
            "Fold 8 started at Tue Jan 14 20:16:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1649]\ttraining's auc: 0.988571\ttraining's auc: 0.988571\tvalid_1's auc: 0.910844\tvalid_1's auc: 0.910844\n",
            "Fold 9 started at Tue Jan 14 20:20:20 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2189]\ttraining's auc: 0.992948\ttraining's auc: 0.992948\tvalid_1's auc: 0.909751\tvalid_1's auc: 0.909751\n",
            "Fold 10 started at Tue Jan 14 20:25:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1241]\ttraining's auc: 0.98203\ttraining's auc: 0.98203\tvalid_1's auc: 0.90673\tvalid_1's auc: 0.90673\n",
            "CV mean score: 0.9098, std: 0.0018.\n",
            "\n",
            "test set contains: ['goal25', 'goal23']\n",
            "\n",
            "start training process... cycle =====> 3\n",
            "use goal columns =====> ['goal23', 'goal25'] to predict ====> goal24\n",
            "\n",
            "Fold 1 started at Tue Jan 14 20:28:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[964]\ttraining's auc: 0.966993\ttraining's auc: 0.966993\tvalid_1's auc: 0.824\tvalid_1's auc: 0.824\n",
            "Fold 2 started at Tue Jan 14 20:31:25 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1426]\ttraining's auc: 0.981845\ttraining's auc: 0.981845\tvalid_1's auc: 0.82987\tvalid_1's auc: 0.82987\n",
            "Fold 3 started at Tue Jan 14 20:35:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1733]\ttraining's auc: 0.987518\ttraining's auc: 0.987518\tvalid_1's auc: 0.824625\tvalid_1's auc: 0.824625\n",
            "Fold 4 started at Tue Jan 14 20:39:43 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[920]\ttraining's auc: 0.966081\ttraining's auc: 0.966081\tvalid_1's auc: 0.826031\tvalid_1's auc: 0.826031\n",
            "Fold 5 started at Tue Jan 14 20:42:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[753]\ttraining's auc: 0.958387\ttraining's auc: 0.958387\tvalid_1's auc: 0.816691\tvalid_1's auc: 0.816691\n",
            "Fold 6 started at Tue Jan 14 20:44:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[481]\ttraining's auc: 0.94063\ttraining's auc: 0.94063\tvalid_1's auc: 0.830516\tvalid_1's auc: 0.830516\n",
            "Fold 7 started at Tue Jan 14 20:45:41 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[774]\ttraining's auc: 0.959204\ttraining's auc: 0.959204\tvalid_1's auc: 0.823829\tvalid_1's auc: 0.823829\n",
            "Fold 8 started at Tue Jan 14 20:47:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1524]\ttraining's auc: 0.985088\ttraining's auc: 0.985088\tvalid_1's auc: 0.81918\tvalid_1's auc: 0.81918\n",
            "Fold 9 started at Tue Jan 14 20:51:48 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2196]\ttraining's auc: 0.992739\ttraining's auc: 0.992739\tvalid_1's auc: 0.818771\tvalid_1's auc: 0.818771\n",
            "Fold 10 started at Tue Jan 14 20:57:28 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1268]\ttraining's auc: 0.977635\ttraining's auc: 0.977635\tvalid_1's auc: 0.834817\tvalid_1's auc: 0.834817\n",
            "CV mean score: 0.8248, std: 0.0054.\n",
            "\n",
            "test set contains: ['goal25', 'goal23', 'goal24']\n",
            "\n",
            "start training process... cycle =====> 4\n",
            "use goal columns =====> ['goal23', 'goal24', 'goal25'] to predict ====> goal22\n",
            "\n",
            "Fold 1 started at Tue Jan 14 21:00:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3841]\ttraining's auc: 0.92221\ttraining's auc: 0.92221\tvalid_1's auc: 0.769098\tvalid_1's auc: 0.769098\n",
            "Fold 2 started at Tue Jan 14 21:09:42 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[4801]\ttraining's auc: 0.938737\ttraining's auc: 0.938737\tvalid_1's auc: 0.756391\tvalid_1's auc: 0.756391\n",
            "Fold 3 started at Tue Jan 14 21:20:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2881]\ttraining's auc: 0.89963\ttraining's auc: 0.89963\tvalid_1's auc: 0.766357\tvalid_1's auc: 0.766357\n",
            "Fold 4 started at Tue Jan 14 21:27:21 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3868]\ttraining's auc: 0.923914\ttraining's auc: 0.923914\tvalid_1's auc: 0.762964\tvalid_1's auc: 0.762964\n",
            "Fold 5 started at Tue Jan 14 21:36:22 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[4017]\ttraining's auc: 0.924617\ttraining's auc: 0.924617\tvalid_1's auc: 0.767582\tvalid_1's auc: 0.767582\n",
            "Fold 6 started at Tue Jan 14 21:45:44 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3242]\ttraining's auc: 0.909611\ttraining's auc: 0.909611\tvalid_1's auc: 0.778128\tvalid_1's auc: 0.778128\n",
            "Fold 7 started at Tue Jan 14 21:53:21 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2588]\ttraining's auc: 0.891143\ttraining's auc: 0.891143\tvalid_1's auc: 0.774169\tvalid_1's auc: 0.774169\n",
            "Fold 8 started at Tue Jan 14 21:59:44 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3841]\ttraining's auc: 0.922906\ttraining's auc: 0.922906\tvalid_1's auc: 0.768996\tvalid_1's auc: 0.768996\n",
            "Fold 9 started at Tue Jan 14 22:08:47 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3272]\ttraining's auc: 0.909471\ttraining's auc: 0.909471\tvalid_1's auc: 0.767506\tvalid_1's auc: 0.767506\n",
            "Fold 10 started at Tue Jan 14 22:16:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[4239]\ttraining's auc: 0.930463\ttraining's auc: 0.930463\tvalid_1's auc: 0.770578\tvalid_1's auc: 0.770578\n",
            "CV mean score: 0.7682, std: 0.0056.\n",
            "\n",
            "test set contains: ['goal25', 'goal23', 'goal24', 'goal22']\n",
            "\n",
            "start training process... cycle =====> 5\n",
            "use goal columns =====> ['goal22', 'goal23', 'goal24', 'goal25'] to predict ====> goal21\n",
            "\n",
            "Fold 1 started at Tue Jan 14 22:26:40 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2170]\ttraining's auc: 0.970381\ttraining's auc: 0.970381\tvalid_1's auc: 0.824595\tvalid_1's auc: 0.824595\n",
            "Fold 2 started at Tue Jan 14 22:32:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1808]\ttraining's auc: 0.962165\ttraining's auc: 0.962165\tvalid_1's auc: 0.835584\tvalid_1's auc: 0.835584\n",
            "Fold 3 started at Tue Jan 14 22:37:15 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1316]\ttraining's auc: 0.947603\ttraining's auc: 0.947603\tvalid_1's auc: 0.83923\tvalid_1's auc: 0.83923\n",
            "Fold 4 started at Tue Jan 14 22:40:53 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1692]\ttraining's auc: 0.959489\ttraining's auc: 0.959489\tvalid_1's auc: 0.831043\tvalid_1's auc: 0.831043\n",
            "Fold 5 started at Tue Jan 14 22:45:26 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1598]\ttraining's auc: 0.956484\ttraining's auc: 0.956484\tvalid_1's auc: 0.831113\tvalid_1's auc: 0.831113\n",
            "Fold 6 started at Tue Jan 14 22:49:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1463]\ttraining's auc: 0.953117\ttraining's auc: 0.953117\tvalid_1's auc: 0.833033\tvalid_1's auc: 0.833033\n",
            "Fold 7 started at Tue Jan 14 22:53:44 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1524]\ttraining's auc: 0.953878\ttraining's auc: 0.953878\tvalid_1's auc: 0.841195\tvalid_1's auc: 0.841195\n",
            "Fold 8 started at Tue Jan 14 22:57:52 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1789]\ttraining's auc: 0.96221\ttraining's auc: 0.96221\tvalid_1's auc: 0.838827\tvalid_1's auc: 0.838827\n",
            "Fold 9 started at Tue Jan 14 23:02:39 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1127]\ttraining's auc: 0.93942\ttraining's auc: 0.93942\tvalid_1's auc: 0.811093\tvalid_1's auc: 0.811093\n",
            "Fold 10 started at Tue Jan 14 23:05:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1404]\ttraining's auc: 0.951244\ttraining's auc: 0.951244\tvalid_1's auc: 0.811583\tvalid_1's auc: 0.811583\n",
            "CV mean score: 0.8297, std: 0.0103.\n",
            "\n",
            "test set contains: ['goal25', 'goal23', 'goal24', 'goal22', 'goal21']\n",
            "process completed successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JCet-RK4bbg2",
        "colab": {}
      },
      "source": [
        "probas.reset_index(drop=True, inplace=True)\n",
        "probas.to_csv( os.path.join(colab_path,'sub2_1_base.csv') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MAV2BnGfTN",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 0.7416860\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB-_K8jaHn84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
        "\n",
        "to_scale = ['NDAYS_FROM_LAST', 'ORDER_OF_BUY', 'field12', 'field13', 'field17', 'DAYS_BEFORE_DEPART', 'field22', 'field25', 'field19', 'USR_CNT',\n",
        "            'field1_field14', 'field26_field27', 'field26']+['field1', 'field14', 'TICKET_CHILD_1Y', 'field27']\n",
        "drop_cols = ['orderid', 'userid', 'QUARTER']#, 'field1', 'field14', 'TICKET_CHILD_1Y', 'field26', 'field27'] #'indicator_goal21' 'indicator_goal22'\n",
        "\n",
        "def combining_ds_stratagy(scaling=StandardScaler(), cols_to_scale=to_scale, \n",
        "                          cols_to_drop=drop_cols):\n",
        "\n",
        "    train = load_ottrip_without_userid_encoding()\n",
        "    test = load_ottrip_without_userid_encoding(train=False)\n",
        "    # print(f\"Shape of raw data\\ntrain: {train.shape}, test: {test.shape}\")\n",
        "    print('='*5)\n",
        "\n",
        "    goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "    th = len(train)\n",
        "    df_all = pd.concat([train.drop(columns=goals_cols+['goal1'],axis=1), test])\n",
        "    print(f\"Shape of combined data: {df_all.shape}\")\n",
        "\n",
        "    # gen features\n",
        "    df_all['userid'] = LabelEncoder().fit_transform(df_all.userid)\n",
        "    df_all['USR_CNT'] = df_all.userid.map(df_all.groupby('userid').size())\n",
        "    df_all = feature_engineering(df_all)\n",
        "\n",
        "    # scaling\n",
        "    df_all[cols_to_scale] = scaling.fit_transform(df_all[cols_to_scale])\n",
        "    df_all = reduce_mem_usage(df_all, verbose=False)\n",
        "\n",
        "    # split df_all\n",
        "    X = df_all[:th].drop(cols_to_drop, axis=1)\n",
        "    X_test = df_all[th:].drop(cols_to_drop, axis=1)\n",
        "    X_test.reset_index(drop=True, inplace=True)\n",
        "    targets = train.loc[:, ['goal1']+goals_cols]\n",
        "\n",
        "    print('='*5)\n",
        "    print(f\"Shape of res data\\nX: {X.shape}, X_test: {X_test.shape}, targets: {targets.shape}\")\n",
        "\n",
        "    return X, X_test, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcQSLoaoGmju",
        "colab_type": "code",
        "outputId": "e41d263a-2bbe-4c12-d135-019a9bac4da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "with timer('Prepare data to train'):\n",
        "    X, X_test, targets = combining_ds_stratagy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 16.08 Mb (74.3% reduction)\n",
            "(196056, 44)\n",
            "Mem. usage decreased to 34.71 Mb (72.0% reduction)\n",
            "(455011, 38)\n",
            "=====\n",
            "Shape of combined data: (651067, 38)\n",
            "Mem. usage decreased to 201.17 Mb (8.2% reduction)\n",
            "=====\n",
            "Shape of res data\n",
            "X: (196056, 70), X_test: (455011, 70), targets: (196056, 6)\n",
            "[Prepare data to train] done in 230 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpCZ0j68GmQf",
        "colab_type": "code",
        "outputId": "40351d96-fb58-465a-ac7d-4476e41f0148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df_scores = pd.DataFrame(index=goals_cols, columns=['avg', 'std'])\n",
        "\n",
        "for col in goals_cols:\n",
        "\n",
        "    print(f'target: {col}')\n",
        "    Y = targets[col]\n",
        "\n",
        "    n_fold = 10\n",
        "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n",
        "\n",
        "    res_dict=train_model_classification(X=X, X_test=X_test, y=Y, params=params_, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                                  columns=None, plot_feature_importance=False, model=None,\n",
        "                                  verbose=10000, early_stopping_rounds=200, n_estimators=1000)\n",
        "   \n",
        "    df[col] = res_dict['prediction'][:, 1]\n",
        "    df_scores.ix[col, 'avg'] = np.round(np.mean(res_dict['scores']), 4)\n",
        "    df_scores.ix[col, 'std'] = np.round(np.std(res_dict['scores']), 4)\n",
        "    \n",
        "    print(f'{col} completed!')\n",
        "    print('='*5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: goal21\n",
            "Fold 1 started at Wed Jan 15 09:30:56 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.918849\ttraining's auc: 0.918849\tvalid_1's auc: 0.751318\tvalid_1's auc: 0.751318\n",
            "Fold 2 started at Wed Jan 15 09:33:36 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.917567\ttraining's auc: 0.917567\tvalid_1's auc: 0.766854\tvalid_1's auc: 0.766854\n",
            "Fold 3 started at Wed Jan 15 09:36:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.916689\ttraining's auc: 0.916689\tvalid_1's auc: 0.763677\tvalid_1's auc: 0.763677\n",
            "Fold 4 started at Wed Jan 15 09:38:55 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.918827\ttraining's auc: 0.918827\tvalid_1's auc: 0.75965\tvalid_1's auc: 0.75965\n",
            "Fold 5 started at Wed Jan 15 09:41:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.918038\ttraining's auc: 0.918038\tvalid_1's auc: 0.753824\tvalid_1's auc: 0.753824\n",
            "Fold 6 started at Wed Jan 15 09:44:11 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.918727\ttraining's auc: 0.918727\tvalid_1's auc: 0.763667\tvalid_1's auc: 0.763667\n",
            "Fold 7 started at Wed Jan 15 09:46:47 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.919868\ttraining's auc: 0.919868\tvalid_1's auc: 0.760771\tvalid_1's auc: 0.760771\n",
            "Fold 8 started at Wed Jan 15 09:49:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.918037\ttraining's auc: 0.918037\tvalid_1's auc: 0.763736\tvalid_1's auc: 0.763736\n",
            "Fold 9 started at Wed Jan 15 09:51:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.91849\ttraining's auc: 0.91849\tvalid_1's auc: 0.758169\tvalid_1's auc: 0.758169\n",
            "Fold 10 started at Wed Jan 15 09:54:21 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.917749\ttraining's auc: 0.917749\tvalid_1's auc: 0.748472\tvalid_1's auc: 0.748472\n",
            "CV mean score: 0.7590, std: 0.0057.\n",
            "goal21 complited!\n",
            "=====\n",
            "target: goal22\n",
            "Fold 1 started at Wed Jan 15 09:56:52 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.818549\ttraining's auc: 0.818549\tvalid_1's auc: 0.735298\tvalid_1's auc: 0.735298\n",
            "Fold 2 started at Wed Jan 15 09:59:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.818205\ttraining's auc: 0.818205\tvalid_1's auc: 0.743852\tvalid_1's auc: 0.743852\n",
            "Fold 3 started at Wed Jan 15 10:02:08 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.817457\ttraining's auc: 0.817457\tvalid_1's auc: 0.745088\tvalid_1's auc: 0.745088\n",
            "Fold 4 started at Wed Jan 15 10:04:45 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.816523\ttraining's auc: 0.816523\tvalid_1's auc: 0.748391\tvalid_1's auc: 0.748391\n",
            "Fold 5 started at Wed Jan 15 10:07:22 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.817531\ttraining's auc: 0.817531\tvalid_1's auc: 0.747996\tvalid_1's auc: 0.747996\n",
            "Fold 6 started at Wed Jan 15 10:10:00 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.817653\ttraining's auc: 0.817653\tvalid_1's auc: 0.745523\tvalid_1's auc: 0.745523\n",
            "Fold 7 started at Wed Jan 15 10:12:38 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.816644\ttraining's auc: 0.816644\tvalid_1's auc: 0.74323\tvalid_1's auc: 0.74323\n",
            "Fold 8 started at Wed Jan 15 10:15:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.817463\ttraining's auc: 0.817463\tvalid_1's auc: 0.751808\tvalid_1's auc: 0.751808\n",
            "Fold 9 started at Wed Jan 15 10:17:42 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.817267\ttraining's auc: 0.817267\tvalid_1's auc: 0.748879\tvalid_1's auc: 0.748879\n",
            "Fold 10 started at Wed Jan 15 10:20:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.816541\ttraining's auc: 0.816541\tvalid_1's auc: 0.744877\tvalid_1's auc: 0.744877\n",
            "CV mean score: 0.7455, std: 0.0042.\n",
            "goal22 complited!\n",
            "=====\n",
            "target: goal23\n",
            "Fold 1 started at Wed Jan 15 10:22:48 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978113\ttraining's auc: 0.978113\tvalid_1's auc: 0.911059\tvalid_1's auc: 0.911059\n",
            "Fold 2 started at Wed Jan 15 10:25:02 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977881\ttraining's auc: 0.977881\tvalid_1's auc: 0.906149\tvalid_1's auc: 0.906149\n",
            "Fold 3 started at Wed Jan 15 10:27:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977807\ttraining's auc: 0.977807\tvalid_1's auc: 0.913267\tvalid_1's auc: 0.913267\n",
            "Fold 4 started at Wed Jan 15 10:29:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978083\ttraining's auc: 0.978083\tvalid_1's auc: 0.904428\tvalid_1's auc: 0.904428\n",
            "Fold 5 started at Wed Jan 15 10:31:45 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977489\ttraining's auc: 0.977489\tvalid_1's auc: 0.907905\tvalid_1's auc: 0.907905\n",
            "Fold 6 started at Wed Jan 15 10:34:00 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978147\ttraining's auc: 0.978147\tvalid_1's auc: 0.904981\tvalid_1's auc: 0.904981\n",
            "Fold 7 started at Wed Jan 15 10:36:15 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.97779\ttraining's auc: 0.97779\tvalid_1's auc: 0.902428\tvalid_1's auc: 0.902428\n",
            "Fold 8 started at Wed Jan 15 10:38:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978271\ttraining's auc: 0.978271\tvalid_1's auc: 0.912812\tvalid_1's auc: 0.912812\n",
            "Fold 9 started at Wed Jan 15 10:40:57 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978223\ttraining's auc: 0.978223\tvalid_1's auc: 0.909258\tvalid_1's auc: 0.909258\n",
            "Fold 10 started at Wed Jan 15 10:43:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978523\ttraining's auc: 0.978523\tvalid_1's auc: 0.906876\tvalid_1's auc: 0.906876\n",
            "CV mean score: 0.9079, std: 0.0035.\n",
            "goal23 complited!\n",
            "=====\n",
            "target: goal24\n",
            "Fold 1 started at Wed Jan 15 10:45:39 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[626]\ttraining's auc: 0.95185\ttraining's auc: 0.95185\tvalid_1's auc: 0.822001\tvalid_1's auc: 0.822001\n",
            "Fold 2 started at Wed Jan 15 10:47:34 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.970492\ttraining's auc: 0.970492\tvalid_1's auc: 0.803772\tvalid_1's auc: 0.803772\n",
            "Fold 3 started at Wed Jan 15 10:50:06 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.970083\ttraining's auc: 0.970083\tvalid_1's auc: 0.827844\tvalid_1's auc: 0.827844\n",
            "Fold 4 started at Wed Jan 15 10:52:39 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.969266\ttraining's auc: 0.969266\tvalid_1's auc: 0.807955\tvalid_1's auc: 0.807955\n",
            "Fold 5 started at Wed Jan 15 10:55:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.969774\ttraining's auc: 0.969774\tvalid_1's auc: 0.823912\tvalid_1's auc: 0.823912\n",
            "Fold 6 started at Wed Jan 15 10:57:36 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.96952\ttraining's auc: 0.96952\tvalid_1's auc: 0.814929\tvalid_1's auc: 0.814929\n",
            "Fold 7 started at Wed Jan 15 11:00:04 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.970804\ttraining's auc: 0.970804\tvalid_1's auc: 0.820693\tvalid_1's auc: 0.820693\n",
            "Fold 8 started at Wed Jan 15 11:02:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.969317\ttraining's auc: 0.969317\tvalid_1's auc: 0.823492\tvalid_1's auc: 0.823492\n",
            "Fold 9 started at Wed Jan 15 11:05:04 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.971178\ttraining's auc: 0.971178\tvalid_1's auc: 0.817947\tvalid_1's auc: 0.817947\n",
            "Fold 10 started at Wed Jan 15 11:07:34 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.970829\ttraining's auc: 0.970829\tvalid_1's auc: 0.815943\tvalid_1's auc: 0.815943\n",
            "CV mean score: 0.8178, std: 0.0071.\n",
            "goal24 complited!\n",
            "=====\n",
            "target: goal25\n",
            "Fold 1 started at Wed Jan 15 11:10:05 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[762]\ttraining's auc: 0.98813\ttraining's auc: 0.98813\tvalid_1's auc: 0.938131\tvalid_1's auc: 0.938131\n",
            "Fold 2 started at Wed Jan 15 11:12:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[627]\ttraining's auc: 0.984605\ttraining's auc: 0.984605\tvalid_1's auc: 0.946175\tvalid_1's auc: 0.946175\n",
            "Fold 3 started at Wed Jan 15 11:14:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.991493\ttraining's auc: 0.991493\tvalid_1's auc: 0.940641\tvalid_1's auc: 0.940641\n",
            "Fold 4 started at Wed Jan 15 11:16:42 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[777]\ttraining's auc: 0.988583\ttraining's auc: 0.988583\tvalid_1's auc: 0.94569\tvalid_1's auc: 0.94569\n",
            "Fold 5 started at Wed Jan 15 11:19:00 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.991592\ttraining's auc: 0.991592\tvalid_1's auc: 0.937042\tvalid_1's auc: 0.937042\n",
            "Fold 6 started at Wed Jan 15 11:21:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[606]\ttraining's auc: 0.984175\ttraining's auc: 0.984175\tvalid_1's auc: 0.948221\tvalid_1's auc: 0.948221\n",
            "Fold 7 started at Wed Jan 15 11:23:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[761]\ttraining's auc: 0.987814\ttraining's auc: 0.987814\tvalid_1's auc: 0.951293\tvalid_1's auc: 0.951293\n",
            "Fold 8 started at Wed Jan 15 11:25:40 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.991917\ttraining's auc: 0.991917\tvalid_1's auc: 0.945462\tvalid_1's auc: 0.945462\n",
            "Fold 9 started at Wed Jan 15 11:28:11 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.991988\ttraining's auc: 0.991988\tvalid_1's auc: 0.936321\tvalid_1's auc: 0.936321\n",
            "Fold 10 started at Wed Jan 15 11:30:44 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.991888\ttraining's auc: 0.991888\tvalid_1's auc: 0.948025\tvalid_1's auc: 0.948025\n",
            "CV mean score: 0.9437, std: 0.0050.\n",
            "goal25 complited!\n",
            "=====\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7qJoc_hGmMj",
        "colab_type": "code",
        "outputId": "74767f15-9d55-48be-d786-0792285546d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(df_scores.avg).T@ np.array([0.28, 0.27, 0.09, 0.18, 0.18])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.812586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPvx3SGdwuA",
        "colab_type": "code",
        "outputId": "f1085bd3-d1ad-4c91-9ff2-6ac80968dd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>goal21</th>\n",
              "      <td>0.759</td>\n",
              "      <td>0.0057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal22</th>\n",
              "      <td>0.7455</td>\n",
              "      <td>0.0042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal23</th>\n",
              "      <td>0.9079</td>\n",
              "      <td>0.0035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal24</th>\n",
              "      <td>0.8178</td>\n",
              "      <td>0.0071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal25</th>\n",
              "      <td>0.9437</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           avg     std\n",
              "goal21   0.759  0.0057\n",
              "goal22  0.7455  0.0042\n",
              "goal23  0.9079  0.0035\n",
              "goal24  0.8178  0.0071\n",
              "goal25  0.9437   0.005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_wk7isMfcGv",
        "colab_type": "code",
        "outputId": "f603798b-1549-4e51-d3c2-5dbd0058159d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>goal21</th>\n",
              "      <th>goal22</th>\n",
              "      <th>goal23</th>\n",
              "      <th>goal24</th>\n",
              "      <th>goal25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.029837</td>\n",
              "      <td>0.169828</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.001767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.007735</td>\n",
              "      <td>0.034065</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.017248</td>\n",
              "      <td>0.008566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.104764</td>\n",
              "      <td>0.002281</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.206103</td>\n",
              "      <td>0.115626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.044303</td>\n",
              "      <td>0.189240</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.028805</td>\n",
              "      <td>0.002812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011501</td>\n",
              "      <td>0.059940</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.009681</td>\n",
              "      <td>0.022574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455006</th>\n",
              "      <td>0.092496</td>\n",
              "      <td>0.217951</td>\n",
              "      <td>0.099113</td>\n",
              "      <td>0.026423</td>\n",
              "      <td>0.000124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455007</th>\n",
              "      <td>0.024383</td>\n",
              "      <td>0.150280</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.016947</td>\n",
              "      <td>0.003121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455008</th>\n",
              "      <td>0.041138</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.110432</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455009</th>\n",
              "      <td>0.042838</td>\n",
              "      <td>0.182646</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.091486</td>\n",
              "      <td>0.000463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455010</th>\n",
              "      <td>0.033454</td>\n",
              "      <td>0.302528</td>\n",
              "      <td>0.134798</td>\n",
              "      <td>0.022921</td>\n",
              "      <td>0.012702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455011 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          goal21    goal22    goal23    goal24    goal25\n",
              "0       0.029837  0.169828  0.000192  0.000070  0.001767\n",
              "1       0.007735  0.034065  0.000059  0.017248  0.008566\n",
              "2       0.104764  0.002281  0.000054  0.206103  0.115626\n",
              "3       0.044303  0.189240  0.000122  0.028805  0.002812\n",
              "4       0.011501  0.059940  0.000062  0.009681  0.022574\n",
              "...          ...       ...       ...       ...       ...\n",
              "455006  0.092496  0.217951  0.099113  0.026423  0.000124\n",
              "455007  0.024383  0.150280  0.048058  0.016947  0.003121\n",
              "455008  0.041138  0.236278  0.110432  0.000063  0.000152\n",
              "455009  0.042838  0.182646  0.000047  0.091486  0.000463\n",
              "455010  0.033454  0.302528  0.134798  0.022921  0.012702\n",
              "\n",
              "[455011 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXEuJ3JR0-V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv( os.path.join(colab_subm_path,'subm2_2.csv') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kpwk1yeIjCD",
        "colab_type": "text"
      },
      "source": [
        "## 2.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieMMjeEyIpM8",
        "colab_type": "code",
        "outputId": "609b555d-eb3e-41eb-f4f0-0118c308679a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "with timer('Prepare data to train'):\n",
        "    X, X_test, targets = combining_ds_stratagy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 16.08 Mb (74.3% reduction)\n",
            "(196056, 44)\n",
            "Mem. usage decreased to 34.71 Mb (72.0% reduction)\n",
            "(455011, 38)\n",
            "=====\n",
            "Shape of combined data: (651067, 38)\n",
            "Mem. usage decreased to 201.17 Mb (8.2% reduction)\n",
            "=====\n",
            "Shape of res data\n",
            "X: (196056, 70), X_test: (455011, 70), targets: (196056, 6)\n",
            "[Prepare data to train] done in 348 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcdqO-WdI4Yi",
        "colab_type": "code",
        "outputId": "69d7b82f-a3ea-403f-aae1-4308fb12cde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "params_ = {'boosting': 'gbdt',\n",
        "          'objective':'binary',\n",
        "          'metric': 'auc',\n",
        "          'learning_rate': 0.01, # 0.003! #0.005 #0.006 \n",
        "          'num_leaves': 110, #110 #100 #150 large, but over-fitting\n",
        "          'max_bin': 66,  #60 #50 # large,but slower,over-fitting\n",
        "          'max_depth': 10, # deal with over-fitting\n",
        "          'min_data_in_leaf': 30, # deal with over-fitting\n",
        "          'min_child_samples': 20,\n",
        "          'feature_fraction': 0.5,#0.5 #0.6 #0.8\n",
        "          'bagging_fraction': 0.8,\n",
        "          'bagging_freq': 40,#5  \n",
        "          'bagging_seed': 11,\n",
        "          'lambda_l1': 2,#1.3! #5 #1.2 #1\n",
        "          'lambda_l2': 0.1,\n",
        "           'random_state': SEED\n",
        "         }\n",
        "\n",
        "goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "df_res = pd.DataFrame()\n",
        "df_scores = pd.DataFrame(index=goals_cols, columns=['avg', 'std'])\n",
        "\n",
        "for col in goals_cols:\n",
        "\n",
        "    print(f'target: {col}')\n",
        "    Y = targets[col]\n",
        "\n",
        "    n_fold = 10\n",
        "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n",
        "\n",
        "    res_dict=train_model_classification(X=X, X_test=X_test, y=Y, params=params_, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                                  columns=None, plot_feature_importance=False, model=None,\n",
        "                                  verbose=10000, early_stopping_rounds=200, n_estimators=5000)\n",
        "  \n",
        "    df_res[col] = res_dict['prediction'][:, 1]\n",
        "    df_scores.ix[col, 'avg'] = np.round(np.mean(res_dict['scores']), 4)\n",
        "    df_scores.ix[col, 'std'] = np.round(np.std(res_dict['scores']), 4)\n",
        "    \n",
        "    print(f'{col} completed!')\n",
        "    print('='*5)\n",
        "\n",
        "df_res.to_csv( os.path.join(colab_subm_path, 'subm2_3.csv') )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: goal21\n",
            "Fold 1 started at Wed Jan 15 15:19:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1778]\ttraining's auc: 0.956298\ttraining's auc: 0.956298\tvalid_1's auc: 0.756079\tvalid_1's auc: 0.756079\n",
            "Fold 2 started at Wed Jan 15 15:24:59 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1805]\ttraining's auc: 0.956598\ttraining's auc: 0.956598\tvalid_1's auc: 0.772257\tvalid_1's auc: 0.772257\n",
            "Fold 3 started at Wed Jan 15 15:30:27 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1370]\ttraining's auc: 0.938029\ttraining's auc: 0.938029\tvalid_1's auc: 0.765064\tvalid_1's auc: 0.765064\n",
            "Fold 4 started at Wed Jan 15 15:34:36 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1237]\ttraining's auc: 0.933542\ttraining's auc: 0.933542\tvalid_1's auc: 0.760945\tvalid_1's auc: 0.760945\n",
            "Fold 5 started at Wed Jan 15 15:38:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1645]\ttraining's auc: 0.951565\ttraining's auc: 0.951565\tvalid_1's auc: 0.757241\tvalid_1's auc: 0.757241\n",
            "Fold 6 started at Wed Jan 15 15:43:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2086]\ttraining's auc: 0.965475\ttraining's auc: 0.965475\tvalid_1's auc: 0.767996\tvalid_1's auc: 0.767996\n",
            "Fold 7 started at Wed Jan 15 15:49:57 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2100]\ttraining's auc: 0.964888\ttraining's auc: 0.964888\tvalid_1's auc: 0.77138\tvalid_1's auc: 0.77138\n",
            "Fold 8 started at Wed Jan 15 15:56:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1950]\ttraining's auc: 0.960687\ttraining's auc: 0.960687\tvalid_1's auc: 0.768538\tvalid_1's auc: 0.768538\n",
            "Fold 9 started at Wed Jan 15 16:02:14 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1506]\ttraining's auc: 0.947261\ttraining's auc: 0.947261\tvalid_1's auc: 0.760515\tvalid_1's auc: 0.760515\n",
            "Fold 10 started at Wed Jan 15 16:06:55 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1718]\ttraining's auc: 0.95337\ttraining's auc: 0.95337\tvalid_1's auc: 0.751104\tvalid_1's auc: 0.751104\n",
            "CV mean score: 0.7631, std: 0.0067.\n",
            "goal21 completed!\n",
            "=====\n",
            "target: goal22\n",
            "Fold 1 started at Wed Jan 15 16:12:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's auc: 0.942297\ttraining's auc: 0.942297\tvalid_1's auc: 0.750244\tvalid_1's auc: 0.750244\n",
            "Fold 2 started at Wed Jan 15 16:25:09 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2724]\ttraining's auc: 0.894462\ttraining's auc: 0.894462\tvalid_1's auc: 0.751098\tvalid_1's auc: 0.751098\n",
            "Fold 3 started at Wed Jan 15 16:32:51 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3448]\ttraining's auc: 0.913079\ttraining's auc: 0.913079\tvalid_1's auc: 0.754902\tvalid_1's auc: 0.754902\n",
            "Fold 4 started at Wed Jan 15 16:42:24 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3091]\ttraining's auc: 0.903392\ttraining's auc: 0.903392\tvalid_1's auc: 0.758182\tvalid_1's auc: 0.758182\n",
            "Fold 5 started at Wed Jan 15 16:51:00 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[4075]\ttraining's auc: 0.927066\ttraining's auc: 0.927066\tvalid_1's auc: 0.760533\tvalid_1's auc: 0.760533\n",
            "Fold 6 started at Wed Jan 15 17:02:15 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[4432]\ttraining's auc: 0.932515\ttraining's auc: 0.932515\tvalid_1's auc: 0.756188\tvalid_1's auc: 0.756188\n",
            "Fold 7 started at Wed Jan 15 17:14:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3919]\ttraining's auc: 0.923339\ttraining's auc: 0.923339\tvalid_1's auc: 0.754965\tvalid_1's auc: 0.754965\n",
            "Fold 8 started at Wed Jan 15 17:24:54 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3815]\ttraining's auc: 0.921861\ttraining's auc: 0.921861\tvalid_1's auc: 0.761367\tvalid_1's auc: 0.761367\n",
            "Fold 9 started at Wed Jan 15 17:35:26 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3794]\ttraining's auc: 0.921747\ttraining's auc: 0.921747\tvalid_1's auc: 0.759048\tvalid_1's auc: 0.759048\n",
            "Fold 10 started at Wed Jan 15 17:45:43 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3965]\ttraining's auc: 0.924745\ttraining's auc: 0.924745\tvalid_1's auc: 0.755047\tvalid_1's auc: 0.755047\n",
            "CV mean score: 0.7562, std: 0.0035.\n",
            "goal22 completed!\n",
            "=====\n",
            "target: goal23\n",
            "Fold 1 started at Wed Jan 15 17:56:38 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1304]\ttraining's auc: 0.983805\ttraining's auc: 0.983805\tvalid_1's auc: 0.911581\tvalid_1's auc: 0.911581\n",
            "Fold 2 started at Wed Jan 15 18:00:25 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1374]\ttraining's auc: 0.984533\ttraining's auc: 0.984533\tvalid_1's auc: 0.9075\tvalid_1's auc: 0.9075\n",
            "Fold 3 started at Wed Jan 15 18:04:27 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1221]\ttraining's auc: 0.98273\ttraining's auc: 0.98273\tvalid_1's auc: 0.914057\tvalid_1's auc: 0.914057\n",
            "Fold 4 started at Wed Jan 15 18:08:02 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2103]\ttraining's auc: 0.992689\ttraining's auc: 0.992689\tvalid_1's auc: 0.906896\tvalid_1's auc: 0.906896\n",
            "Fold 5 started at Wed Jan 15 18:14:06 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1919]\ttraining's auc: 0.991208\ttraining's auc: 0.991208\tvalid_1's auc: 0.909831\tvalid_1's auc: 0.909831\n",
            "Fold 6 started at Wed Jan 15 18:19:40 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2109]\ttraining's auc: 0.992608\ttraining's auc: 0.992608\tvalid_1's auc: 0.906552\tvalid_1's auc: 0.906552\n",
            "Fold 7 started at Wed Jan 15 18:25:47 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1530]\ttraining's auc: 0.987215\ttraining's auc: 0.987215\tvalid_1's auc: 0.904074\tvalid_1's auc: 0.904074\n",
            "Fold 8 started at Wed Jan 15 18:30:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2100]\ttraining's auc: 0.992401\ttraining's auc: 0.992401\tvalid_1's auc: 0.915184\tvalid_1's auc: 0.915184\n",
            "Fold 9 started at Wed Jan 15 18:36:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1556]\ttraining's auc: 0.987989\ttraining's auc: 0.987989\tvalid_1's auc: 0.91004\tvalid_1's auc: 0.91004\n",
            "Fold 10 started at Wed Jan 15 18:40:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1793]\ttraining's auc: 0.990088\ttraining's auc: 0.990088\tvalid_1's auc: 0.908692\tvalid_1's auc: 0.908692\n",
            "CV mean score: 0.9094, std: 0.0033.\n",
            "goal23 completed!\n",
            "=====\n",
            "target: goal24\n",
            "Fold 1 started at Wed Jan 15 18:46:04 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[626]\ttraining's auc: 0.95185\ttraining's auc: 0.95185\tvalid_1's auc: 0.822001\tvalid_1's auc: 0.822001\n",
            "Fold 2 started at Wed Jan 15 18:48:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1099]\ttraining's auc: 0.974\ttraining's auc: 0.974\tvalid_1's auc: 0.804031\tvalid_1's auc: 0.804031\n",
            "Fold 3 started at Wed Jan 15 18:51:41 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1047]\ttraining's auc: 0.971788\ttraining's auc: 0.971788\tvalid_1's auc: 0.82877\tvalid_1's auc: 0.82877\n",
            "Fold 4 started at Wed Jan 15 18:55:04 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[972]\ttraining's auc: 0.968313\ttraining's auc: 0.968313\tvalid_1's auc: 0.808124\tvalid_1's auc: 0.808124\n",
            "Fold 5 started at Wed Jan 15 18:58:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1411]\ttraining's auc: 0.982117\ttraining's auc: 0.982117\tvalid_1's auc: 0.826247\tvalid_1's auc: 0.826247\n",
            "Fold 6 started at Wed Jan 15 19:02:40 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1607]\ttraining's auc: 0.985406\ttraining's auc: 0.985406\tvalid_1's auc: 0.817658\tvalid_1's auc: 0.817658\n",
            "Fold 7 started at Wed Jan 15 19:07:41 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[880]\ttraining's auc: 0.965573\ttraining's auc: 0.965573\tvalid_1's auc: 0.821673\tvalid_1's auc: 0.821673\n",
            "Fold 8 started at Wed Jan 15 19:10:34 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1441]\ttraining's auc: 0.982948\ttraining's auc: 0.982948\tvalid_1's auc: 0.824116\tvalid_1's auc: 0.824116\n",
            "Fold 9 started at Wed Jan 15 19:15:07 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[948]\ttraining's auc: 0.968875\ttraining's auc: 0.968875\tvalid_1's auc: 0.818337\tvalid_1's auc: 0.818337\n",
            "Fold 10 started at Wed Jan 15 19:18:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[997]\ttraining's auc: 0.970729\ttraining's auc: 0.970729\tvalid_1's auc: 0.815959\tvalid_1's auc: 0.815959\n",
            "CV mean score: 0.8187, std: 0.0074.\n",
            "goal24 completed!\n",
            "=====\n",
            "target: goal25\n",
            "Fold 1 started at Wed Jan 15 19:21:26 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[762]\ttraining's auc: 0.98813\ttraining's auc: 0.98813\tvalid_1's auc: 0.938131\tvalid_1's auc: 0.938131\n",
            "Fold 2 started at Wed Jan 15 19:23:58 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[627]\ttraining's auc: 0.984605\ttraining's auc: 0.984605\tvalid_1's auc: 0.946175\tvalid_1's auc: 0.946175\n",
            "Fold 3 started at Wed Jan 15 19:26:04 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[971]\ttraining's auc: 0.991102\ttraining's auc: 0.991102\tvalid_1's auc: 0.940771\tvalid_1's auc: 0.940771\n",
            "Fold 4 started at Wed Jan 15 19:29:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[777]\ttraining's auc: 0.988583\ttraining's auc: 0.988583\tvalid_1's auc: 0.94569\tvalid_1's auc: 0.94569\n",
            "Fold 5 started at Wed Jan 15 19:31:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[993]\ttraining's auc: 0.991518\ttraining's auc: 0.991518\tvalid_1's auc: 0.937074\tvalid_1's auc: 0.937074\n",
            "Fold 6 started at Wed Jan 15 19:34:59 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[606]\ttraining's auc: 0.984175\ttraining's auc: 0.984175\tvalid_1's auc: 0.948221\tvalid_1's auc: 0.948221\n",
            "Fold 7 started at Wed Jan 15 19:37:02 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[761]\ttraining's auc: 0.987814\ttraining's auc: 0.987814\tvalid_1's auc: 0.951293\tvalid_1's auc: 0.951293\n",
            "Fold 8 started at Wed Jan 15 19:39:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[839]\ttraining's auc: 0.989312\ttraining's auc: 0.989312\tvalid_1's auc: 0.94569\tvalid_1's auc: 0.94569\n",
            "Fold 9 started at Wed Jan 15 19:42:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[858]\ttraining's auc: 0.989577\ttraining's auc: 0.989577\tvalid_1's auc: 0.936807\tvalid_1's auc: 0.936807\n",
            "Fold 10 started at Wed Jan 15 19:45:05 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[975]\ttraining's auc: 0.991552\ttraining's auc: 0.991552\tvalid_1's auc: 0.948146\tvalid_1's auc: 0.948146\n",
            "CV mean score: 0.9438, std: 0.0049.\n",
            "goal25 completed!\n",
            "=====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e7a80f8add28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolab_subm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subm2_3.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQIhZtDqM-12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res.to_csv( os.path.join(colab_subm_path, 'subm2_3.csv') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUm8FCbDGCdw",
        "colab_type": "text"
      },
      "source": [
        "## 2.4  0.740581"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcUVrsEiGKEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
        "\n",
        "to_scale = ['NDAYS_FROM_LAST', 'ORDER_OF_BUY', 'field12', 'field13', 'field17', 'DAYS_BEFORE_DEPART', 'field22', 'field25', 'field19', 'USR_CNT',\n",
        "            'field1_field14', 'field26_field27', 'field26']#+['field1', 'field14', 'TICKET_CHILD_1Y', 'field27']\n",
        "drop_cols = ['orderid', 'userid', 'QUARTER']#, 'field1', 'field14', 'TICKET_CHILD_1Y', 'field26', 'field27'] #'indicator_goal21' 'indicator_goal22'\n",
        "\n",
        "def combining_ds_stratagy(scaling=StandardScaler(), cols_to_scale=to_scale, \n",
        "                          cols_to_drop=drop_cols):\n",
        "\n",
        "    train = load_ottrip_without_userid_encoding()\n",
        "    test = load_ottrip_without_userid_encoding(train=False)\n",
        "    # print(f\"Shape of raw data\\ntrain: {train.shape}, test: {test.shape}\")\n",
        "    print('='*5)\n",
        "\n",
        "    goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "    th = len(train)\n",
        "    df_all = pd.concat([train.drop(columns=goals_cols+['goal1'],axis=1), test])\n",
        "    print(f\"Shape of combined data: {df_all.shape}\")\n",
        "\n",
        "    # gen features\n",
        "    df_all['userid'] = LabelEncoder().fit_transform(df_all.userid)\n",
        "    df_all['USR_CNT'] = df_all.userid.map(df_all.groupby('userid').size())\n",
        "    df_all = feature_engineering(df_all)\n",
        "\n",
        "    # scaling\n",
        "    df_all[cols_to_scale] = scaling.fit_transform(df_all[cols_to_scale])\n",
        "    df_all = reduce_mem_usage(df_all, verbose=False)\n",
        "\n",
        "    # split df_all\n",
        "    X = df_all[:th].drop(cols_to_drop, axis=1)\n",
        "    X_test = df_all[th:].drop(cols_to_drop, axis=1)\n",
        "    X_test.reset_index(drop=True, inplace=True)\n",
        "    targets = train.loc[:, ['goal1']+goals_cols]\n",
        "\n",
        "    print('='*5)\n",
        "    print(f\"Shape of res data\\nX: {X.shape}, X_test: {X_test.shape}, targets: {targets.shape}\")\n",
        "\n",
        "    return X, X_test, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s25CXNtUGLq4",
        "colab_type": "code",
        "outputId": "fc37ff90-e08e-4369-96fd-68ce6799a67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "with timer('Prepare data to train'):\n",
        "    X, X_test, targets = combining_ds_stratagy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 16.08 Mb (74.3% reduction)\n",
            "(196056, 44)\n",
            "Mem. usage decreased to 34.71 Mb (72.0% reduction)\n",
            "(455011, 38)\n",
            "=====\n",
            "Shape of combined data: (651067, 38)\n",
            "Mem. usage decreased to 201.17 Mb (8.2% reduction)\n",
            "=====\n",
            "Shape of res data\n",
            "X: (196056, 70), X_test: (455011, 70), targets: (196056, 6)\n",
            "[Prepare data to train] done in 302 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8JeK_KuGLji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_parameters={'bagging_fraction': 0.9654895756771754, 'bagging_freq': 48, \n",
        "                'colsample_bytree': 0.6316618472598627, \n",
        "                'feature_fraction': 0.563032101936602, 'lambda_l1': 2.3387198763414423, \n",
        "                'lambda_l2': 1.1374415101532467, 'learning_rate': 0.01, 'max_bin': 44, 'max_depth': 24, \n",
        "                'min_child_samples': 428, 'min_child_weight': 1, 'min_data_in_leaf': 21, \n",
        "                'num_leaves': 83, 'reg_alpha': 5, #'is_unbalanced': True, \n",
        "                'reg_lambda': 5, 'subsample': 0.4380014780786996}\n",
        "\n",
        "#'n_estimators': 2822"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcZhPZq1GLcB",
        "colab_type": "code",
        "outputId": "e1d93581-3369-46ee-9489-cb13533a2e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "df_res = pd.DataFrame()\n",
        "df_scores = pd.DataFrame(index=goals_cols, columns=['avg', 'std'])\n",
        "\n",
        "for col in goals_cols:\n",
        "\n",
        "    print(f'target: {col}')\n",
        "    Y = targets[col]\n",
        "\n",
        "    n_fold = 10\n",
        "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n",
        "\n",
        "    res_dict=train_model_classification(X=X, X_test=X_test, y=Y, params=opt_parameters, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                                  columns=None, plot_feature_importance=False, model=None,\n",
        "                                  verbose=10000, early_stopping_rounds=200, n_estimators=2822)\n",
        "  \n",
        "    df_res[col] = res_dict['prediction'][:, 1]\n",
        "    df_scores.ix[col, 'avg'] = np.round(np.mean(res_dict['scores']), 4)\n",
        "    df_scores.ix[col, 'std'] = np.round(np.std(res_dict['scores']), 4)\n",
        "    df_res.to_csv( os.path.join(colab_subm_path, f'{col}_subm2_4_opt_params.csv') )\n",
        "    print(f'{col} completed!')\n",
        "    print('='*5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: goal21\n",
            "Fold 1 started at Fri Jan 17 12:50:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2611]\ttraining's binary_logloss: 0.0918673\ttraining's auc: 0.95942\tvalid_1's binary_logloss: 0.140097\tvalid_1's auc: 0.756332\n",
            "Fold 2 started at Fri Jan 17 12:57:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2582]\ttraining's binary_logloss: 0.0918528\ttraining's auc: 0.960685\tvalid_1's binary_logloss: 0.142165\tvalid_1's auc: 0.770626\n",
            "Fold 3 started at Fri Jan 17 13:04:41 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1606]\ttraining's binary_logloss: 0.105915\ttraining's auc: 0.930943\tvalid_1's binary_logloss: 0.133009\tvalid_1's auc: 0.764659\n",
            "Fold 4 started at Fri Jan 17 13:09:17 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2061]\ttraining's binary_logloss: 0.098742\ttraining's auc: 0.947352\tvalid_1's binary_logloss: 0.136658\tvalid_1's auc: 0.766134\n",
            "Fold 5 started at Fri Jan 17 13:15:02 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1932]\ttraining's binary_logloss: 0.100235\ttraining's auc: 0.941153\tvalid_1's binary_logloss: 0.144513\tvalid_1's auc: 0.755728\n",
            "Fold 6 started at Fri Jan 17 13:20:27 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2191]\ttraining's binary_logloss: 0.0969007\ttraining's auc: 0.95087\tvalid_1's binary_logloss: 0.139072\tvalid_1's auc: 0.762894\n",
            "Fold 7 started at Fri Jan 17 13:26:27 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2351]\ttraining's binary_logloss: 0.0950014\ttraining's auc: 0.954447\tvalid_1's binary_logloss: 0.139119\tvalid_1's auc: 0.76584\n",
            "Fold 8 started at Fri Jan 17 13:32:50 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2247]\ttraining's binary_logloss: 0.0963693\ttraining's auc: 0.9523\tvalid_1's binary_logloss: 0.136894\tvalid_1's auc: 0.768472\n",
            "Fold 9 started at Fri Jan 17 13:38:57 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2017]\ttraining's binary_logloss: 0.0994627\ttraining's auc: 0.943549\tvalid_1's binary_logloss: 0.141365\tvalid_1's auc: 0.76115\n",
            "Fold 10 started at Fri Jan 17 13:44:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1883]\ttraining's binary_logloss: 0.101292\ttraining's auc: 0.939804\tvalid_1's binary_logloss: 0.140748\tvalid_1's auc: 0.751811\n",
            "CV mean score: 0.7624, std: 0.0058.\n",
            "goal21 completed!\n",
            "=====\n",
            "target: goal22\n",
            "Fold 1 started at Fri Jan 17 13:49:52 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332265\ttraining's auc: 0.873782\tvalid_1's binary_logloss: 0.392521\tvalid_1's auc: 0.744314\n",
            "Fold 2 started at Fri Jan 17 13:56:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332423\ttraining's auc: 0.873035\tvalid_1's binary_logloss: 0.396952\tvalid_1's auc: 0.749905\n",
            "Fold 3 started at Fri Jan 17 14:03:45 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.33278\ttraining's auc: 0.873098\tvalid_1's binary_logloss: 0.39252\tvalid_1's auc: 0.752884\n",
            "Fold 4 started at Fri Jan 17 14:10:38 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332616\ttraining's auc: 0.873094\tvalid_1's binary_logloss: 0.390191\tvalid_1's auc: 0.755679\n",
            "Fold 5 started at Fri Jan 17 14:17:36 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332526\ttraining's auc: 0.872873\tvalid_1's binary_logloss: 0.394291\tvalid_1's auc: 0.755025\n",
            "Fold 6 started at Fri Jan 17 14:24:35 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.33289\ttraining's auc: 0.873209\tvalid_1's binary_logloss: 0.389087\tvalid_1's auc: 0.751579\n",
            "Fold 7 started at Fri Jan 17 14:31:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.333398\ttraining's auc: 0.87204\tvalid_1's binary_logloss: 0.387847\tvalid_1's auc: 0.750813\n",
            "Fold 8 started at Fri Jan 17 14:38:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332946\ttraining's auc: 0.873509\tvalid_1's binary_logloss: 0.390882\tvalid_1's auc: 0.757051\n",
            "Fold 9 started at Fri Jan 17 14:45:15 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332249\ttraining's auc: 0.872349\tvalid_1's binary_logloss: 0.39622\tvalid_1's auc: 0.754317\n",
            "Fold 10 started at Fri Jan 17 14:52:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2822]\ttraining's binary_logloss: 0.332316\ttraining's auc: 0.872779\tvalid_1's binary_logloss: 0.393951\tvalid_1's auc: 0.753662\n",
            "CV mean score: 0.7525, std: 0.0035.\n",
            "goal22 completed!\n",
            "=====\n",
            "target: goal23\n",
            "Fold 1 started at Fri Jan 17 14:59:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1834]\ttraining's binary_logloss: 0.0764833\ttraining's auc: 0.98603\tvalid_1's binary_logloss: 0.107277\tvalid_1's auc: 0.912619\n",
            "Fold 2 started at Fri Jan 17 15:04:01 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1988]\ttraining's binary_logloss: 0.0745924\ttraining's auc: 0.98695\tvalid_1's binary_logloss: 0.109776\tvalid_1's auc: 0.908251\n",
            "Fold 3 started at Fri Jan 17 15:09:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1825]\ttraining's binary_logloss: 0.0765788\ttraining's auc: 0.985595\tvalid_1's binary_logloss: 0.108039\tvalid_1's auc: 0.915913\n",
            "Fold 4 started at Fri Jan 17 15:13:58 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2066]\ttraining's binary_logloss: 0.0739255\ttraining's auc: 0.987556\tvalid_1's binary_logloss: 0.105913\tvalid_1's auc: 0.907758\n",
            "Fold 5 started at Fri Jan 17 15:19:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1970]\ttraining's binary_logloss: 0.0749514\ttraining's auc: 0.986536\tvalid_1's binary_logloss: 0.105913\tvalid_1's auc: 0.908432\n",
            "Fold 6 started at Fri Jan 17 15:24:35 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2041]\ttraining's binary_logloss: 0.073984\ttraining's auc: 0.987122\tvalid_1's binary_logloss: 0.110174\tvalid_1's auc: 0.907802\n",
            "Fold 7 started at Fri Jan 17 15:29:47 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1974]\ttraining's binary_logloss: 0.0745573\ttraining's auc: 0.98696\tvalid_1's binary_logloss: 0.111005\tvalid_1's auc: 0.904151\n",
            "Fold 8 started at Fri Jan 17 15:34:53 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2489]\ttraining's binary_logloss: 0.0698138\ttraining's auc: 0.990667\tvalid_1's binary_logloss: 0.103247\tvalid_1's auc: 0.914541\n",
            "Fold 9 started at Fri Jan 17 15:41:15 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1946]\ttraining's binary_logloss: 0.0744218\ttraining's auc: 0.98672\tvalid_1's binary_logloss: 0.116672\tvalid_1's auc: 0.908329\n",
            "Fold 10 started at Fri Jan 17 15:46:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1308]\ttraining's binary_logloss: 0.0823968\ttraining's auc: 0.978323\tvalid_1's binary_logloss: 0.11734\tvalid_1's auc: 0.908275\n",
            "CV mean score: 0.9096, std: 0.0034.\n",
            "goal23 completed!\n",
            "=====\n",
            "target: goal24\n",
            "Fold 1 started at Fri Jan 17 15:49:50 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1054]\ttraining's binary_logloss: 0.0661299\ttraining's auc: 0.961429\tvalid_1's binary_logloss: 0.0928676\tvalid_1's auc: 0.821393\n",
            "Fold 2 started at Fri Jan 17 15:53:01 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1122]\ttraining's binary_logloss: 0.0652571\ttraining's auc: 0.964109\tvalid_1's binary_logloss: 0.0889901\tvalid_1's auc: 0.802583\n",
            "Fold 3 started at Fri Jan 17 15:56:26 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1660]\ttraining's binary_logloss: 0.0581573\ttraining's auc: 0.977209\tvalid_1's binary_logloss: 0.0912659\tvalid_1's auc: 0.827977\n",
            "Fold 4 started at Fri Jan 17 16:01:11 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[967]\ttraining's binary_logloss: 0.067182\ttraining's auc: 0.956911\tvalid_1's binary_logloss: 0.0933218\tvalid_1's auc: 0.812103\n",
            "Fold 5 started at Fri Jan 17 16:04:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2136]\ttraining's binary_logloss: 0.0529786\ttraining's auc: 0.985335\tvalid_1's binary_logloss: 0.0882697\tvalid_1's auc: 0.824382\n",
            "Fold 6 started at Fri Jan 17 16:10:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2018]\ttraining's binary_logloss: 0.0539575\ttraining's auc: 0.984096\tvalid_1's binary_logloss: 0.0892483\tvalid_1's auc: 0.816694\n",
            "Fold 7 started at Fri Jan 17 16:15:56 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1572]\ttraining's binary_logloss: 0.0586486\ttraining's auc: 0.976276\tvalid_1's binary_logloss: 0.0938667\tvalid_1's auc: 0.823054\n",
            "Fold 8 started at Fri Jan 17 16:20:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1213]\ttraining's binary_logloss: 0.0639192\ttraining's auc: 0.965767\tvalid_1's binary_logloss: 0.0920224\tvalid_1's auc: 0.824353\n",
            "Fold 9 started at Fri Jan 17 16:24:09 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1527]\ttraining's binary_logloss: 0.0601031\ttraining's auc: 0.975368\tvalid_1's binary_logloss: 0.0864237\tvalid_1's auc: 0.817916\n",
            "Fold 10 started at Fri Jan 17 16:28:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2358]\ttraining's binary_logloss: 0.0509725\ttraining's auc: 0.987482\tvalid_1's binary_logloss: 0.0876467\tvalid_1's auc: 0.817672\n",
            "CV mean score: 0.8188, std: 0.0070.\n",
            "goal24 completed!\n",
            "=====\n",
            "target: goal25\n",
            "Fold 1 started at Fri Jan 17 16:35:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[737]\ttraining's binary_logloss: 0.0355533\ttraining's auc: 0.982267\tvalid_1's binary_logloss: 0.0497435\tvalid_1's auc: 0.938569\n",
            "Fold 2 started at Fri Jan 17 16:37:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1004]\ttraining's binary_logloss: 0.0319821\ttraining's auc: 0.987101\tvalid_1's binary_logloss: 0.0539468\tvalid_1's auc: 0.946244\n",
            "Fold 3 started at Fri Jan 17 16:40:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[942]\ttraining's binary_logloss: 0.0332931\ttraining's auc: 0.985887\tvalid_1's binary_logloss: 0.0473566\tvalid_1's auc: 0.940827\n",
            "Fold 4 started at Fri Jan 17 16:43:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1002]\ttraining's binary_logloss: 0.0328101\ttraining's auc: 0.986911\tvalid_1's binary_logloss: 0.0447949\tvalid_1's auc: 0.946081\n",
            "Fold 5 started at Fri Jan 17 16:46:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[945]\ttraining's binary_logloss: 0.0328079\ttraining's auc: 0.986509\tvalid_1's binary_logloss: 0.0513542\tvalid_1's auc: 0.935927\n",
            "Fold 6 started at Fri Jan 17 16:49:27 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[744]\ttraining's binary_logloss: 0.0356378\ttraining's auc: 0.981866\tvalid_1's binary_logloss: 0.0499076\tvalid_1's auc: 0.949666\n",
            "Fold 7 started at Fri Jan 17 16:51:48 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1151]\ttraining's binary_logloss: 0.0308876\ttraining's auc: 0.989176\tvalid_1's binary_logloss: 0.0493807\tvalid_1's auc: 0.951495\n",
            "Fold 8 started at Fri Jan 17 16:55:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1154]\ttraining's binary_logloss: 0.030663\ttraining's auc: 0.989013\tvalid_1's binary_logloss: 0.0506939\tvalid_1's auc: 0.946832\n",
            "Fold 9 started at Fri Jan 17 16:58:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[861]\ttraining's binary_logloss: 0.0338244\ttraining's auc: 0.984589\tvalid_1's binary_logloss: 0.0533492\tvalid_1's auc: 0.937412\n",
            "Fold 10 started at Fri Jan 17 17:01:25 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[955]\ttraining's binary_logloss: 0.0329988\ttraining's auc: 0.986375\tvalid_1's binary_logloss: 0.0485064\tvalid_1's auc: 0.947492\n",
            "CV mean score: 0.9441, std: 0.0052.\n",
            "goal25 completed!\n",
            "=====\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVEKAC4WGLNT",
        "colab_type": "code",
        "outputId": "dad0c140-6afd-4635-d94f-e28cfd934712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>goal21</th>\n",
              "      <td>0.7624</td>\n",
              "      <td>0.0058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal22</th>\n",
              "      <td>0.7525</td>\n",
              "      <td>0.0035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal23</th>\n",
              "      <td>0.9096</td>\n",
              "      <td>0.0034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal24</th>\n",
              "      <td>0.8188</td>\n",
              "      <td>0.007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal25</th>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.0052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           avg     std\n",
              "goal21  0.7624  0.0058\n",
              "goal22  0.7525  0.0035\n",
              "goal23  0.9096  0.0034\n",
              "goal24  0.8188   0.007\n",
              "goal25  0.9441  0.0052"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puD5BjJWGLFh",
        "colab_type": "code",
        "outputId": "bb553a90-1ffc-48c8-c6e4-3aadf9667044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "t=.2\n",
        "f, axes = plt.subplots(2, 3, figsize=(20, 6), sharex=True)\n",
        "sns.distplot( df_res[\"goal21\"][df_res[\"goal21\"]>t] , color=\"skyblue\", ax=axes[0, 0])\n",
        "sns.distplot( df_res[\"goal22\"][df_res[\"goal22\"]>t] , color=\"olive\", ax=axes[0, 1])\n",
        "sns.distplot( df_res[\"goal23\"][df_res[\"goal23\"]>t] , color=\"gold\", ax=axes[0, 2])\n",
        "sns.distplot( df_res[\"goal24\"][df_res[\"goal24\"]>t] , color=\"teal\", ax=axes[1, 0])\n",
        "sns.distplot( df_res[\"goal25\"][df_res[\"goal25\"]>t] , color=\"red\", ax=axes[1, 1]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAFzCAYAAABIE85gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJQszUdGK-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res.to_csv( os.path.join(colab_subm_path, 'subm2_4_opt_params.csv') ) # 0.740581"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgL9ZLFnJLSR",
        "colab_type": "text"
      },
      "source": [
        "## 2.5 with different hyperparameters LGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs5i7ugQJYfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "colab_train_path = pathlib.Path('/content/drive/My Drive/ott_train')\n",
        "Xtrain = pd.read_pickle(colab_train_path/'train.pkl')\n",
        "Xtest = pd.read_pickle(colab_train_path/'test.pkl')\n",
        "targets = pd.read_pickle(colab_train_path/'targets.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdC0M4gFJZvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_goal22_1={'bagging_fraction': 0.7583949890486377, \n",
        "                     'bagging_freq': 30, \n",
        "                     'colsample_bytree': 0.5957847319300573, \n",
        "                     'feature_fraction': 0.5701469943379747, \n",
        "                     'lambda_l1': 1.6024810478481566, \n",
        "                     'lambda_l2': 0.13008005451818686, \n",
        "                     'learning_rate': 0.01, \n",
        "                     'max_bin': 82, \n",
        "                     'max_depth': 22, \n",
        "                     'min_child_samples': 384, \n",
        "                     'min_child_weight': 0.1, \n",
        "                     'min_data_in_leaf': 15, \n",
        "                    #  'n_estimators': 3420, \n",
        "                     'num_leaves': 160, \n",
        "                     'reg_alpha': 1, \n",
        "                     'reg_lambda': 20, \n",
        "                     'subsample': 0.34621894292890626}\n",
        "\n",
        "\n",
        "opt_goal21_1={'bagging_fraction': 0.9654895756771754, \n",
        "                     'bagging_freq': 48, \n",
        "                     'colsample_bytree': 0.6316618472598627, \n",
        "                     'feature_fraction': 0.563032101936602, \n",
        "                     'lambda_l1': 2.3387198763414423, \n",
        "                     'lambda_l2': 1.1374415101532467, \n",
        "                     'learning_rate': 0.01, \n",
        "                     'max_bin': 44, \n",
        "                     'max_depth': 24, \n",
        "                     'min_child_samples': 428, \n",
        "                     'min_child_weight': 1, \n",
        "                     'min_data_in_leaf': 21,\n",
        "                    #  'n_estimators': 2822, \n",
        "                     'num_leaves': 83, \n",
        "                     'reg_alpha': 5, \n",
        "                     'reg_lambda': 5, \n",
        "                     'subsample': 0.4380014780786996}\n",
        "\n",
        "optuna_goal25_1={'lambda_l1': 0.07339506600611748,\n",
        "                 'lambda_l2': 7.169086661812628e-06,\n",
        "                 'num_leaves': 87,\n",
        "                 'feature_fraction': 0.8319575690963853,\n",
        "                 'bagging_fraction': 0.9962276128702263,\n",
        "                 'bagging_freq': 5,\n",
        "                #  'n_estimators': 3764,\n",
        "                 'min_child_samples': 69 }\n",
        "\n",
        "\n",
        "optuna_goal24_1={'lambda_l1': 9.391821397592286,\n",
        "                 'lambda_l2': 0.00012006755910102027,\n",
        "                 'num_leaves': 191,\n",
        "                 'feature_fraction': 0.6023281072584363,\n",
        "                 'bagging_fraction': 0.9717980271300153,\n",
        "                 'bagging_freq': 1,\n",
        "                #  'n_estimators': 3176,\n",
        "                 'min_child_samples': 72 }\n",
        "\n",
        "\n",
        "params_ = {'boosting': 'gbdt',\n",
        "          'objective':'binary',\n",
        "          'metric': 'auc',\n",
        "          'learning_rate': 0.01, # 0.003! #0.005 #0.006 \n",
        "          'num_leaves': 110, #110 #100 #150 large, but over-fitting\n",
        "          'max_bin': 66,  #60 #50 # large,but slower,over-fitting\n",
        "          'max_depth': 10, # deal with over-fitting\n",
        "          'min_data_in_leaf': 30, # deal with over-fitting\n",
        "          'min_child_samples': 20,\n",
        "          'feature_fraction': 0.5,#0.5 #0.6 #0.8\n",
        "          'bagging_fraction': 0.8,\n",
        "          'bagging_freq': 40,#5  \n",
        "          'bagging_seed': 11,\n",
        "          'lambda_l1': 2,#1.3! #5 #1.2 #1\n",
        "          'lambda_l2': 0.1,\n",
        "           'random_state': SEED }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJYxWgaJRygU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Target = namedtuple('Target', 'name params n_estimators')\n",
        "\n",
        "goal21 = Target(name='goal21', params=opt_goal21_1, n_estimators=2822)\n",
        "goal22 = Target(name='goal22', params=opt_goal22_1, n_estimators=3420)\n",
        "goal23 = Target(name='goal23', params=params_, n_estimators=1000)\n",
        "goal24 = Target(name='goal24', params=optuna_goal24_1, n_estimators=3176)\n",
        "goal25 = Target(name='goal25', params=optuna_goal25_1, n_estimators=3764)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhesgqEJKnpv",
        "colab_type": "code",
        "outputId": "c9e91f6f-33dd-47a7-865d-c216cc04c673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "goals_cols=['goal21', 'goal22', 'goal23', 'goal24', 'goal25']\n",
        "goals_source = [goal21, goal22, goal23, goal24, goal25]\n",
        "df_res = pd.DataFrame()\n",
        "df_scores = pd.DataFrame(index=goals_cols, columns=['avg', 'std'])\n",
        "\n",
        "for Y_source in goals_source:\n",
        "\n",
        "    print(f'target: {Y_source.name}')\n",
        "    Y = targets[Y_source.name]\n",
        "\n",
        "    n_fold = 10\n",
        "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=SEED)\n",
        "\n",
        "    res_dict=train_model_classification(X=Xtrain, X_test=Xtest, y=Y, params=Y_source.params, folds=folds, model_type='lgb', eval_metric='auc', \n",
        "                                  columns=None, plot_feature_importance=False, model=None,\n",
        "                                  verbose=10000, early_stopping_rounds=200, n_estimators=Y_source.n_estimators)\n",
        "  \n",
        "    df_res[Y_source.name] = res_dict['prediction'][:, 1]\n",
        "    df_scores.ix[Y_source.name, 'avg'] = np.round(np.mean(res_dict['scores']), 4)\n",
        "    df_scores.ix[Y_source.name, 'std'] = np.round(np.std(res_dict['scores']), 4)\n",
        "    df_res.to_csv( os.path.join(colab_subm_path, f'{Y_source.name}_subm2_5_different_params.csv') )\n",
        "    print(f'{Y_source.name} completed!')\n",
        "    print('='*5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: goal21\n",
            "Fold 1 started at Sun Jan 19 10:46:42 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2611]\ttraining's binary_logloss: 0.0918673\ttraining's auc: 0.95942\tvalid_1's binary_logloss: 0.140097\tvalid_1's auc: 0.756332\n",
            "Fold 2 started at Sun Jan 19 10:52:08 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2582]\ttraining's binary_logloss: 0.0918528\ttraining's auc: 0.960685\tvalid_1's binary_logloss: 0.142165\tvalid_1's auc: 0.770626\n",
            "Fold 3 started at Sun Jan 19 10:57:30 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1606]\ttraining's binary_logloss: 0.105915\ttraining's auc: 0.930943\tvalid_1's binary_logloss: 0.133009\tvalid_1's auc: 0.764659\n",
            "Fold 4 started at Sun Jan 19 11:01:10 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2061]\ttraining's binary_logloss: 0.098742\ttraining's auc: 0.947352\tvalid_1's binary_logloss: 0.136658\tvalid_1's auc: 0.766134\n",
            "Fold 5 started at Sun Jan 19 11:05:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1932]\ttraining's binary_logloss: 0.100235\ttraining's auc: 0.941153\tvalid_1's binary_logloss: 0.144513\tvalid_1's auc: 0.755728\n",
            "Fold 6 started at Sun Jan 19 11:09:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2191]\ttraining's binary_logloss: 0.0969007\ttraining's auc: 0.95087\tvalid_1's binary_logloss: 0.139072\tvalid_1's auc: 0.762894\n",
            "Fold 7 started at Sun Jan 19 11:14:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2351]\ttraining's binary_logloss: 0.0950014\ttraining's auc: 0.954447\tvalid_1's binary_logloss: 0.139119\tvalid_1's auc: 0.76584\n",
            "Fold 8 started at Sun Jan 19 11:19:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2247]\ttraining's binary_logloss: 0.0963693\ttraining's auc: 0.9523\tvalid_1's binary_logloss: 0.136894\tvalid_1's auc: 0.768472\n",
            "Fold 9 started at Sun Jan 19 11:24:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2017]\ttraining's binary_logloss: 0.0994627\ttraining's auc: 0.943549\tvalid_1's binary_logloss: 0.141365\tvalid_1's auc: 0.76115\n",
            "Fold 10 started at Sun Jan 19 11:28:35 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[1883]\ttraining's binary_logloss: 0.101292\ttraining's auc: 0.939804\tvalid_1's binary_logloss: 0.140748\tvalid_1's auc: 0.751811\n",
            "CV mean score: 0.7624, std: 0.0058.\n",
            "goal21 completed!\n",
            "=====\n",
            "target: goal22\n",
            "Fold 1 started at Sun Jan 19 11:32:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2723]\ttraining's binary_logloss: 0.279437\ttraining's auc: 0.942732\tvalid_1's binary_logloss: 0.389706\tvalid_1's auc: 0.750306\n",
            "Fold 2 started at Sun Jan 19 11:39:07 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2794]\ttraining's binary_logloss: 0.276104\ttraining's auc: 0.947499\tvalid_1's binary_logloss: 0.394657\tvalid_1's auc: 0.753935\n",
            "Fold 3 started at Sun Jan 19 11:45:37 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2993]\ttraining's binary_logloss: 0.271771\ttraining's auc: 0.950387\tvalid_1's binary_logloss: 0.390048\tvalid_1's auc: 0.757285\n",
            "Fold 4 started at Sun Jan 19 11:52:33 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2768]\ttraining's binary_logloss: 0.278463\ttraining's auc: 0.944745\tvalid_1's binary_logloss: 0.387443\tvalid_1's auc: 0.760882\n",
            "Fold 5 started at Sun Jan 19 11:58:56 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3120]\ttraining's binary_logloss: 0.267634\ttraining's auc: 0.954615\tvalid_1's binary_logloss: 0.391962\tvalid_1's auc: 0.759714\n",
            "Fold 6 started at Sun Jan 19 12:06:08 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3173]\ttraining's binary_logloss: 0.267043\ttraining's auc: 0.954854\tvalid_1's binary_logloss: 0.386427\tvalid_1's auc: 0.756819\n",
            "Fold 7 started at Sun Jan 19 12:13:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2762]\ttraining's binary_logloss: 0.279064\ttraining's auc: 0.944093\tvalid_1's binary_logloss: 0.385477\tvalid_1's auc: 0.755497\n",
            "Fold 8 started at Sun Jan 19 12:19:50 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[3420]\ttraining's binary_logloss: 0.259837\ttraining's auc: 0.960758\tvalid_1's binary_logloss: 0.388871\tvalid_1's auc: 0.761522\n",
            "Fold 9 started at Sun Jan 19 12:27:21 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[2432]\ttraining's binary_logloss: 0.288031\ttraining's auc: 0.934542\tvalid_1's binary_logloss: 0.393825\tvalid_1's auc: 0.759146\n",
            "Fold 10 started at Sun Jan 19 12:33:03 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[3042]\ttraining's binary_logloss: 0.269718\ttraining's auc: 0.952541\tvalid_1's binary_logloss: 0.392137\tvalid_1's auc: 0.75685\n",
            "CV mean score: 0.7572, std: 0.0032.\n",
            "goal22 completed!\n",
            "=====\n",
            "target: goal23\n",
            "Fold 1 started at Sun Jan 19 12:40:05 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978113\ttraining's auc: 0.978113\tvalid_1's auc: 0.911059\tvalid_1's auc: 0.911059\n",
            "Fold 2 started at Sun Jan 19 12:42:14 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977881\ttraining's auc: 0.977881\tvalid_1's auc: 0.906149\tvalid_1's auc: 0.906149\n",
            "Fold 3 started at Sun Jan 19 12:44:23 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977807\ttraining's auc: 0.977807\tvalid_1's auc: 0.913267\tvalid_1's auc: 0.913267\n",
            "Fold 4 started at Sun Jan 19 12:46:31 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978083\ttraining's auc: 0.978083\tvalid_1's auc: 0.904428\tvalid_1's auc: 0.904428\n",
            "Fold 5 started at Sun Jan 19 12:48:38 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.977489\ttraining's auc: 0.977489\tvalid_1's auc: 0.907905\tvalid_1's auc: 0.907905\n",
            "Fold 6 started at Sun Jan 19 12:50:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978147\ttraining's auc: 0.978147\tvalid_1's auc: 0.904981\tvalid_1's auc: 0.904981\n",
            "Fold 7 started at Sun Jan 19 12:52:54 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.97779\ttraining's auc: 0.97779\tvalid_1's auc: 0.902428\tvalid_1's auc: 0.902428\n",
            "Fold 8 started at Sun Jan 19 12:55:02 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978271\ttraining's auc: 0.978271\tvalid_1's auc: 0.912812\tvalid_1's auc: 0.912812\n",
            "Fold 9 started at Sun Jan 19 12:57:11 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978223\ttraining's auc: 0.978223\tvalid_1's auc: 0.909258\tvalid_1's auc: 0.909258\n",
            "Fold 10 started at Sun Jan 19 12:59:19 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.978523\ttraining's auc: 0.978523\tvalid_1's auc: 0.906876\tvalid_1's auc: 0.906876\n",
            "CV mean score: 0.9079, std: 0.0035.\n",
            "goal23 completed!\n",
            "=====\n",
            "target: goal24\n",
            "Fold 1 started at Sun Jan 19 13:01:30 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[133]\ttraining's binary_logloss: 0.0610664\ttraining's auc: 0.974415\tvalid_1's binary_logloss: 0.0935576\tvalid_1's auc: 0.815279\n",
            "Fold 2 started at Sun Jan 19 13:02:08 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttraining's binary_logloss: 0.0782829\ttraining's auc: 0.926265\tvalid_1's binary_logloss: 0.0899242\tvalid_1's auc: 0.795293\n",
            "Fold 3 started at Sun Jan 19 13:02:36 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[154]\ttraining's binary_logloss: 0.0585822\ttraining's auc: 0.977971\tvalid_1's binary_logloss: 0.092203\tvalid_1's auc: 0.824479\n",
            "Fold 4 started at Sun Jan 19 13:03:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[91]\ttraining's binary_logloss: 0.0679054\ttraining's auc: 0.958257\tvalid_1's binary_logloss: 0.0946759\tvalid_1's auc: 0.802096\n",
            "Fold 5 started at Sun Jan 19 13:03:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[139]\ttraining's binary_logloss: 0.0607585\ttraining's auc: 0.975802\tvalid_1's binary_logloss: 0.0896587\tvalid_1's auc: 0.814969\n",
            "Fold 6 started at Sun Jan 19 13:04:29 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[177]\ttraining's binary_logloss: 0.0556126\ttraining's auc: 0.982519\tvalid_1's binary_logloss: 0.0905064\tvalid_1's auc: 0.812591\n",
            "Fold 7 started at Sun Jan 19 13:05:12 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[137]\ttraining's binary_logloss: 0.0604119\ttraining's auc: 0.975103\tvalid_1's binary_logloss: 0.0943808\tvalid_1's auc: 0.820144\n",
            "Fold 8 started at Sun Jan 19 13:05:51 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[161]\ttraining's binary_logloss: 0.0576815\ttraining's auc: 0.97921\tvalid_1's binary_logloss: 0.0930976\tvalid_1's auc: 0.814154\n",
            "Fold 9 started at Sun Jan 19 13:06:32 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[113]\ttraining's binary_logloss: 0.0648172\ttraining's auc: 0.967965\tvalid_1's binary_logloss: 0.0874775\tvalid_1's auc: 0.811534\n",
            "Fold 10 started at Sun Jan 19 13:07:08 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[173]\ttraining's binary_logloss: 0.0560893\ttraining's auc: 0.982679\tvalid_1's binary_logloss: 0.0886759\tvalid_1's auc: 0.809193\n",
            "CV mean score: 0.8120, std: 0.0079.\n",
            "goal24 completed!\n",
            "=====\n",
            "target: goal25\n",
            "Fold 1 started at Sun Jan 19 13:07:55 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_logloss: 0.0388107\ttraining's auc: 0.979198\tvalid_1's binary_logloss: 0.052799\tvalid_1's auc: 0.93291\n",
            "Fold 2 started at Sun Jan 19 13:08:22 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[35]\ttraining's binary_logloss: 0.0367344\ttraining's auc: 0.982401\tvalid_1's binary_logloss: 0.0559386\tvalid_1's auc: 0.942659\n",
            "Fold 3 started at Sun Jan 19 13:08:49 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[53]\ttraining's binary_logloss: 0.0331888\ttraining's auc: 0.987209\tvalid_1's binary_logloss: 0.0483108\tvalid_1's auc: 0.938829\n",
            "Fold 4 started at Sun Jan 19 13:09:19 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[47]\ttraining's binary_logloss: 0.034761\ttraining's auc: 0.985516\tvalid_1's binary_logloss: 0.0471255\tvalid_1's auc: 0.93995\n",
            "Fold 5 started at Sun Jan 19 13:09:48 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[60]\ttraining's binary_logloss: 0.0313038\ttraining's auc: 0.989663\tvalid_1's binary_logloss: 0.0531616\tvalid_1's auc: 0.932641\n",
            "Fold 6 started at Sun Jan 19 13:10:18 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[27]\ttraining's binary_logloss: 0.0394584\ttraining's auc: 0.978263\tvalid_1's binary_logloss: 0.0527986\tvalid_1's auc: 0.943854\n",
            "Fold 7 started at Sun Jan 19 13:10:45 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[69]\ttraining's binary_logloss: 0.0301505\ttraining's auc: 0.991246\tvalid_1's binary_logloss: 0.0516538\tvalid_1's auc: 0.94691\n",
            "Fold 8 started at Sun Jan 19 13:11:16 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[56]\ttraining's binary_logloss: 0.0321228\ttraining's auc: 0.988592\tvalid_1's binary_logloss: 0.0535774\tvalid_1's auc: 0.939107\n",
            "Fold 9 started at Sun Jan 19 13:11:46 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_logloss: 0.0388441\ttraining's auc: 0.978774\tvalid_1's binary_logloss: 0.0560364\tvalid_1's auc: 0.932135\n",
            "Fold 10 started at Sun Jan 19 13:12:13 2020\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[36]\ttraining's binary_logloss: 0.0369204\ttraining's auc: 0.982496\tvalid_1's binary_logloss: 0.0499796\tvalid_1's auc: 0.943629\n",
            "CV mean score: 0.9393, std: 0.0050.\n",
            "goal25 completed!\n",
            "=====\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ImlxKCRKnge",
        "colab_type": "code",
        "outputId": "7608ee0c-bf35-4198-f929-6a615a89dd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(df_scores.avg).T@ np.array([0.28, 0.27, 0.09, 0.18, 0.18])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8148610000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg2yskw8DcBl",
        "colab_type": "code",
        "outputId": "2d23fa9e-22c9-4efa-c83d-1313e314637b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>goal21</th>\n",
              "      <td>0.7624</td>\n",
              "      <td>0.0058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal22</th>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.0032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal23</th>\n",
              "      <td>0.9079</td>\n",
              "      <td>0.0035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal24</th>\n",
              "      <td>0.812</td>\n",
              "      <td>0.0079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goal25</th>\n",
              "      <td>0.9393</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           avg     std\n",
              "goal21  0.7624  0.0058\n",
              "goal22  0.7572  0.0032\n",
              "goal23  0.9079  0.0035\n",
              "goal24   0.812  0.0079\n",
              "goal25  0.9393   0.005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4D-LM1nKnS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res.to_csv( os.path.join(colab_subm_path,'subm2_5.csv') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmsiT9NiAMW1",
        "colab_type": "code",
        "outputId": "db391673-0caa-4e1a-92f1-da09974754e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "bins = np.linspace(0., 1.0, 11)\n",
        "g21_cut = pd.cut(df_res.goal21, bins)\n",
        "sns.countplot(g21_cut)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f780098acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEGCAYAAAC+fkgiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7mMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N75eefYxJZmN",
        "colab_type": "code",
        "outputId": "56da8d40-8ec0-4129-b700-a984543e2d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "\n",
        "df_res"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>goal21</th>\n",
              "      <th>goal22</th>\n",
              "      <th>goal23</th>\n",
              "      <th>goal24</th>\n",
              "      <th>goal25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.031965</td>\n",
              "      <td>0.152154</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.002970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.007021</td>\n",
              "      <td>0.029539</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.015290</td>\n",
              "      <td>0.014993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.115634</td>\n",
              "      <td>0.001854</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.205632</td>\n",
              "      <td>0.089961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038684</td>\n",
              "      <td>0.169789</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.033159</td>\n",
              "      <td>0.004034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011673</td>\n",
              "      <td>0.054704</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.006715</td>\n",
              "      <td>0.037602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455006</th>\n",
              "      <td>0.077312</td>\n",
              "      <td>0.177069</td>\n",
              "      <td>0.099113</td>\n",
              "      <td>0.025256</td>\n",
              "      <td>0.000439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455007</th>\n",
              "      <td>0.023484</td>\n",
              "      <td>0.139423</td>\n",
              "      <td>0.048058</td>\n",
              "      <td>0.011652</td>\n",
              "      <td>0.004015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455008</th>\n",
              "      <td>0.046745</td>\n",
              "      <td>0.245868</td>\n",
              "      <td>0.110432</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.000477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455009</th>\n",
              "      <td>0.041133</td>\n",
              "      <td>0.172840</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.102221</td>\n",
              "      <td>0.000592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455010</th>\n",
              "      <td>0.033494</td>\n",
              "      <td>0.275325</td>\n",
              "      <td>0.134798</td>\n",
              "      <td>0.018742</td>\n",
              "      <td>0.027475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455011 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          goal21    goal22    goal23    goal24    goal25\n",
              "0       0.031965  0.152154  0.000192  0.000136  0.002970\n",
              "1       0.007021  0.029539  0.000059  0.015290  0.014993\n",
              "2       0.115634  0.001854  0.000054  0.205632  0.089961\n",
              "3       0.038684  0.169789  0.000122  0.033159  0.004034\n",
              "4       0.011673  0.054704  0.000062  0.006715  0.037602\n",
              "...          ...       ...       ...       ...       ...\n",
              "455006  0.077312  0.177069  0.099113  0.025256  0.000439\n",
              "455007  0.023484  0.139423  0.048058  0.011652  0.004015\n",
              "455008  0.046745  0.245868  0.110432  0.000124  0.000477\n",
              "455009  0.041133  0.172840  0.000047  0.102221  0.000592\n",
              "455010  0.033494  0.275325  0.134798  0.018742  0.027475\n",
              "\n",
              "[455011 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kVD_JFt5IP8U"
      },
      "source": [
        "# TPOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhltafklJSJx",
        "colab": {}
      },
      "source": [
        "# !pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1Zf0IxiFAPM",
        "colab": {}
      },
      "source": [
        "# import joblib\n",
        "import tpot\n",
        "from tpot import TPOTClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OcV4XerUIT1E",
        "outputId": "271fac5f-45e0-4ce5-efa5-3485d8eab5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# from dask.distributed import Client\n",
        "# client = Client(n_workers=4, threads_per_worker=1, processes=False)\n",
        "# client"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Client</h3>\n",
              "<ul>\n",
              "  <li><b>Scheduler: </b>inproc://172.28.0.2/1119/1\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3>Cluster</h3>\n",
              "<ul>\n",
              "  <li><b>Workers: </b>4</li>\n",
              "  <li><b>Cores: </b>4</li>\n",
              "  <li><b>Memory: </b>27.31 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: scheduler='inproc://172.28.0.2/1119/1' processes=4 cores=4>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2QUosg3aIT4B",
        "colab": {}
      },
      "source": [
        "X, X_test, Y, Y_test = train_test_split(features, label, stratify=label, test_size=0.3, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lQpVaSoQqJoV",
        "colab": {}
      },
      "source": [
        "tpot_config = {\n",
        "    \n",
        "        'sklearn.ensemble.ExtraTreesRegressor': {\n",
        "            'n_estimators': [100],\n",
        "            'max_features': np.arange(0.05, 1.01, 0.05),\n",
        "            'min_samples_split': range(2, 21),\n",
        "            'min_samples_leaf': range(1, 21),\n",
        "            'bootstrap': [True, False]\n",
        "        },\n",
        "\n",
        "        'sklearn.tree.DecisionTreeRegressor': {\n",
        "            'max_depth': range(1, 11),\n",
        "            'min_samples_split': range(2, 21),\n",
        "            'min_samples_leaf': range(1, 21)\n",
        "        },\n",
        "\n",
        "        'sklearn.ensemble.RandomForestRegressor': {\n",
        "            'n_estimators': [100],\n",
        "            'max_features': np.arange(0.05, 1.01, 0.05),\n",
        "            'min_samples_split': range(2, 21),\n",
        "            'min_samples_leaf': range(1, 21),\n",
        "            'bootstrap': [True, False]\n",
        "        },\n",
        "\n",
        "\n",
        "        # Preprocesssors\n",
        "        'sklearn.preprocessing.Binarizer': {\n",
        "            'threshold': np.arange(0.0, 1.01, 0.05)\n",
        "        },\n",
        "\n",
        "        'sklearn.decomposition.FastICA': {\n",
        "            'tol': np.arange(0.0, 1.01, 0.05)\n",
        "        },\n",
        "\n",
        "        'sklearn.cluster.FeatureAgglomeration': {\n",
        "            'linkage': ['ward', 'complete', 'average'],\n",
        "            'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.MaxAbsScaler': {\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.MinMaxScaler': {\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.Normalizer': {\n",
        "            'norm': ['l1', 'l2', 'max']\n",
        "        },\n",
        "\n",
        "        'sklearn.kernel_approximation.Nystroem': {\n",
        "            'kernel': ['rbf', 'cosine', 'chi2', 'laplacian', 'polynomial', 'poly', 'linear', 'additive_chi2', 'sigmoid'],\n",
        "            'gamma': np.arange(0.0, 1.01, 0.05),\n",
        "            'n_components': range(1, 11)\n",
        "        },\n",
        "\n",
        "        'sklearn.decomposition.PCA': {\n",
        "            'svd_solver': ['randomized'],\n",
        "            'iterated_power': range(1, 11)\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.PolynomialFeatures': {\n",
        "            'degree': [2],\n",
        "            'include_bias': [False],\n",
        "            'interaction_only': [False]\n",
        "        },\n",
        "\n",
        "        'sklearn.kernel_approximation.RBFSampler': {\n",
        "            'gamma': np.arange(0.0, 1.01, 0.05)\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.RobustScaler': {\n",
        "        },\n",
        "\n",
        "        'sklearn.preprocessing.StandardScaler': {\n",
        "        },\n",
        "\n",
        "        'tpot.builtins.ZeroCount': {\n",
        "        },\n",
        "\n",
        "        'tpot.builtins.OneHotEncoder': {\n",
        "            'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
        "            'sparse': [False],\n",
        "            'threshold': [10]\n",
        "        },\n",
        "\n",
        "        # Selectors\n",
        "        'sklearn.feature_selection.SelectFwe': {\n",
        "            'alpha': np.arange(0, 0.05, 0.001),\n",
        "            'score_func': {\n",
        "                'sklearn.feature_selection.f_regression': None\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'sklearn.feature_selection.SelectPercentile': {\n",
        "            'percentile': range(1, 100),\n",
        "            'score_func': {\n",
        "                'sklearn.feature_selection.f_regression': None\n",
        "            }\n",
        "        },\n",
        "\n",
        "        'sklearn.feature_selection.VarianceThreshold': {\n",
        "            'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
        "        },\n",
        "\n",
        "        'sklearn.feature_selection.SelectFromModel': {\n",
        "            'threshold': np.arange(0, 1.01, 0.05),\n",
        "            'estimator': {\n",
        "                'sklearn.ensemble.ExtraTreesRegressor': {\n",
        "                    'n_estimators': [100],\n",
        "                    'max_features': np.arange(0.05, 1.01, 0.05)\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q2bq7dmpqXad",
        "outputId": "a73a2a6a-8fbb-48b8-f1ca-d27b767d0881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "ea43701c0cb44697bb180648cc97de18",
            "ff945c11c1fb438aa4089d39938616ba",
            "79059ecd6a994b658cc0b0d6136df72a",
            "80bf60894cef4be8a2e43d3c0605fa60",
            "a5df86d604604d9d8dfb6a9a927588b3",
            "5934a5a7d55644108e5993725f83ce95",
            "a4f7266640a24787a3deccb699bb2367",
            "21cf21b8ae344c1cb39688f484935ea7"
          ]
        }
      },
      "source": [
        "folds   = 10\n",
        "# Start the TPOT regression\n",
        "best_model = TPOTClassifier(use_dask=False, n_jobs=-1, config_dict=tpot_config, cv=folds, scoring='roc_auc', max_time_mins=60,\n",
        "                               generations=5, population_size=20, verbosity=2, random_state=SEED) #memory='./PipelineCache',       memory='auto',\n",
        "best_model.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea43701c0cb44697bb180648cc97de18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=20.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "\r61.60 minutes have elapsed. TPOT will close down.\n",
            "TPOT closed during evaluation in one generation.\n",
            "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
            "\r\n",
            "\r\n",
            "TPOT closed prematurely. Will use the current best pipeline.\n",
            "\r\n",
            "Best pipeline: ExtraTreesRegressor(input_matrix, bootstrap=False, max_features=0.15000000000000002, min_samples_leaf=6, min_samples_split=15, n_estimators=100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict={'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
              "                                                                                  'l1',\n",
              "                                                                                  'l2',\n",
              "                                                                                  'manhattan',\n",
              "                                                                                  'cosine'],\n",
              "                                                                     'linkage': ['ward',\n",
              "                                                                                 'complete',\n",
              "                                                                                 'average']},\n",
              "                            'sklearn.decomposition.FastICA': {'tol': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
              "                            'sklearn.decomposition.PCA': {'iterated_power...\n",
              "                            'tpot.builtins.ZeroCount': {}},\n",
              "               crossover_rate=0.1, cv=10, disable_update_check=False,\n",
              "               early_stop=None, generations=5, max_eval_time_mins=5,\n",
              "               max_time_mins=60, memory=None, mutation_rate=0.9, n_jobs=-1,\n",
              "               offspring_size=None, periodic_checkpoint_folder=None,\n",
              "               population_size=20, random_state=17, scoring='roc_auc',\n",
              "               subsample=1.0, template=None, use_dask=False, verbosity=2,\n",
              "               warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wW94_DD0rsvt",
        "colab": {}
      },
      "source": [
        "# Export the TPOT pipeline if you want to use it for anything later\n",
        "if os.path.exists('./Exported Pipelines'):\n",
        "    pass\n",
        "else:\n",
        "    os.mkdir('./Exported Pipelines')\n",
        "best_model.export('./Exported Pipelines/' + ticker_input + '-prediction-pipeline.py')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ta6l27M3IT6m",
        "colab": {}
      },
      "source": [
        "# scale up: Increase the TPOT parameters like population_size, generations\n",
        "tp = TPOTClassifier(\n",
        "    generations=5,\n",
        "    population_size=20,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    random_state=SEED,\n",
        "    verbosity=3, max_time_mins=60, scoring='roc_auc',\n",
        "    config_dict=tpot.config.classifier_config_dict_light,\n",
        "    use_dask=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3IusIbZnTkWu",
        "colab": {}
      },
      "source": [
        "# perform the fit in this context manager\n",
        "# with joblib.parallel_backend(\"dask\"):\n",
        "#     tp.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MSg0gOrXIT9p",
        "outputId": "487c42d1-725d-4844-8727-e1a1fd09ccd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "4effa211e0e04927b762555779af5773",
            "a4220273ab5e42219b88ad4170ca48ba",
            "06f127a8ab964bd1bfef336ed5d9a458",
            "05ae147f4a82477e90d63fc0bd2efd23",
            "24b7a6d00bf8451b8da0fe935ca30650",
            "2328471642d7471e897fa85036e67472",
            "5b0d5656ba644f68b428f2a28e12cc3e",
            "5e5a6186682c492dbc290c9f7370412b"
          ]
        }
      },
      "source": [
        "tp.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31 operators have been imported by TPOT.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4effa211e0e04927b762555779af5773",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=20.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rSkipped pipeline #6 due to time out. Continuing to the next pipeline.\n",
            "\r\n",
            "\r5.10 minutes have elapsed. TPOT will close down.\n",
            "TPOT closed during evaluation in one generation.\n",
            "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
            "\r\n",
            "\r\n",
            "TPOT closed prematurely. Will use the current best pipeline.\n",
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=3,\n",
              "               disable_update_check=False, early_stop=None, generations=5,\n",
              "               max_eval_time_mins=5, max_time_mins=5, memory=None,\n",
              "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
              "               periodic_checkpoint_folder=None, population_size=20,\n",
              "               random_state=17, scoring='roc_auc', subsample=1.0, template=None,\n",
              "               use_dask=False, verbosity=3, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5TEIUyjC7Cgg",
        "colab": {}
      },
      "source": [
        "# set parameters\n",
        "gens = 2                                              # 100 gens is default, takes 2 days on 32 cores\n",
        "pop_size = 5                                          # population size per gen\n",
        "max_time_mins = None                                  # cap on training time\n",
        "\n",
        "# Instantiate tpot classifier\n",
        "tpot = TPOTClassifier(generations=gens,               # number of generations to run\n",
        "                      population_size=pop_size,       # number of models in a generation\n",
        "                      max_time_mins=max_time_mins,    # maximum time to train\n",
        "                      scoring='roc_auc',              # score with respect to roc_auc\n",
        "                      verbosity=2,                    # verbosity of the model \n",
        "                      n_jobs=-1,                      # this tells the model to use as many cores as it can find!\n",
        "                      random_state=2017)              # random state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E0YXrF5I7VYs",
        "outputId": "120f5fe6-7ac4-4d4d-9da9-f102604496a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "81f55b507d084ed888cd3ad4219c6093",
            "57823476d44c49c883619e583c433378",
            "915409f20fa84b02966d3a519a564276",
            "2fb378c35df04c079be611e5df985ec9",
            "c05d9070741e4b2286692364f41bb507",
            "7121e8647a6745deb573eea2f9a754be",
            "11c4801327544003a1a504d0ac38eb88",
            "f578a356739e4c1ab0bd19d1c42a8ebd"
          ]
        }
      },
      "source": [
        "tpot.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81f55b507d084ed888cd3ad4219c6093",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=15.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 - Current best internal CV score: 0.6775898058168919\n",
            "Generation 2 - Current best internal CV score: 0.6775898058168919\n",
            "\n",
            "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.001, max_depth=9, max_features=0.25, min_samples_leaf=8, min_samples_split=10, n_estimators=100, subsample=0.7000000000000001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "               disable_update_check=False, early_stop=None, generations=2,\n",
              "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
              "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
              "               periodic_checkpoint_folder=None, population_size=5,\n",
              "               random_state=2017, scoring='roc_auc', subsample=1.0,\n",
              "               template=None, use_dask=False, verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hm8qSz6y6QOh",
        "outputId": "3ea7ed15-781b-4a0a-bf68-3c1a8f27ee52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Test roc auc score:\\t{tpot.score(X_test, Y_test)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test roc auc score:\t0.6748026595079117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PJOny6u_DUv-",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from sklearn.preprocessing import Binarizer, Normalizer\n",
        "from tpot.builtins import StackingEstimator\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = make_pipeline(\n",
        "    StackingEstimator(estimator=LogisticRegression(C=5.0, dual=False, penalty=\"l2\")),\n",
        "    StackingEstimator(estimator=XGBClassifier(learning_rate=1.0, max_depth=1, min_child_weight=12, n_estimators=100, nthread=1, subsample=0.7500000000000001)),\n",
        "    Normalizer(norm=\"max\"),\n",
        "    StackingEstimator(estimator=LogisticRegression(C=0.5, dual=False, penalty=\"l1\")),\n",
        "    StackingEstimator(estimator=LogisticRegression(C=0.5, dual=False, penalty=\"l1\")),\n",
        "    Binarizer(threshold=0.25),\n",
        "    XGBClassifier(learning_rate=0.001, max_depth=1, min_child_weight=10, n_estimators=100, nthread=1, subsample=1.0)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CMdyeK0hDXOg",
        "outputId": "45dcd9bf-ad64-45b2-97da-17db0ceeba4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('stackingestimator-1',\n",
              "                 StackingEstimator(estimator=LogisticRegression(C=5.0,\n",
              "                                                                class_weight=None,\n",
              "                                                                dual=False,\n",
              "                                                                fit_intercept=True,\n",
              "                                                                intercept_scaling=1,\n",
              "                                                                l1_ratio=None,\n",
              "                                                                max_iter=100,\n",
              "                                                                multi_class='warn',\n",
              "                                                                n_jobs=None,\n",
              "                                                                penalty='l2',\n",
              "                                                                random_state=None,\n",
              "                                                                solver='warn',\n",
              "                                                                tol=0.0001,\n",
              "                                                                verbose=0,\n",
              "                                                                warm_start=False))),\n",
              "                ('stackingestimator-2',\n",
              "                 StackingEst...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.001,\n",
              "                               max_delta_step=0, max_depth=1,\n",
              "                               min_child_weight=10, missing=None,\n",
              "                               n_estimators=100, n_jobs=1, nthread=1,\n",
              "                               objective='binary:logistic', random_state=0,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1.0,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4FqxdxQTD7d5",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlcFbFYFD7kC",
        "colab": {}
      },
      "source": [
        "# export_best_pipeline = False\n",
        "\n",
        "# if export_best_pipeline:\n",
        "#     tpot.export(TPOT_DIR / 'tpot_idn_pipeline.py')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IOWocihBD7pg",
        "colab": {}
      },
      "source": [
        "y_prob_series = pd.Series(y_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J-uilY_wFRNB",
        "outputId": "5b3caaab-eb8b-4111-c6c3-3eab807790af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "y_prob_series.plot.hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f23bdd40f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD6CAYAAABgZXp6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlfb/AeY1bD+yrEj2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t-ZnPHIrelSd",
        "colab": {}
      },
      "source": [
        "exctracted_best_model = tp.fitted_pipeline_.steps[-1][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0G-vLchi6r32",
        "outputId": "dfd18abb-650e-48f4-b59a-eb0705054084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "exctracted_best_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=18, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=1, objective='binary:logistic', random_state=17,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=0.7500000000000001, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BwUZSqQWeoX_",
        "outputId": "16a04509-825e-4b1f-8173-28798f0e1cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "exctracted_best_model.fit(X, Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
              "              min_child_weight=18, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=1, objective='binary:logistic', random_state=17,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=0.7500000000000001, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sGjZ06WDflLO",
        "colab": {}
      },
      "source": [
        "predictions = exctracted_best_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOi61sIMIUAq",
        "outputId": "d9bd765b-fb12-4e62-dc33-257ebd91d06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tp.score(X_test, Y_test))\n",
        "# pipeline_optimizer.export('tpot_exported_pipeline.py')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9778635428532567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSy0Cavsao52",
        "outputId": "891ea770-da2e-47f3-ab93-7e79b282d3e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tp.score(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.665772723685386\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}